{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xRCyaQP3wmpK"
      },
      "source": [
        "# Work space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLjWnDAZwRpb",
        "outputId": "bc5dbdf2-fbc7-4841-9fb2-12d1cc397cc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ipython-autotime in /usr/local/lib/python3.10/dist-packages (0.3.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from ipython-autotime) (7.34.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (67.7.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.18.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (3.0.38)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (2.14.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->ipython-autotime) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->ipython-autotime) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ipython-autotime) (0.2.6)\n",
            "time: 481 µs (started: 2023-06-06 07:25:51 +00:00)\n"
          ]
        }
      ],
      "source": [
        "!pip install ipython-autotime\n",
        "%load_ext autotime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJIu9I8zknsQ",
        "outputId": "27445b16-5c7d-4812-b61a-1f05db288419"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/.shortcut-targets-by-id/16CLBs4KTeHKahxECZFQFwRxk3_khT2VI/data_mining/final_project/Code/source_code\n",
            "\u001b[0m\u001b[01;34mdataset\u001b[0m/                      recommendation_thien_2.ipynb  \u001b[01;34mresults\u001b[0m/\n",
            "\u001b[01;34mPhoBERT\u001b[0m/                      recommendation_thien_3.ipynb  Thien.ipynb\n",
            "recommendation_kiet.ipynb     recommendation_thien.ipynb\n",
            "recommendation_thien_1.ipynb  recommendation_v1.ipynb\n",
            "time: 6.47 s (started: 2023-06-06 07:25:51 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Import nessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# import country_converter as coco\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-JOssHW1i-p1"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmHg-eunjDRL",
        "outputId": "1f67d39b-31dc-4fb9-a9cc-14fcc05181d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/16CLBs4KTeHKahxECZFQFwRxk3_khT2VI/data_mining/final_project/Code/source_code/PhoBERT\n",
            "/content/drive/.shortcut-targets-by-id/16CLBs4KTeHKahxECZFQFwRxk3_khT2VI/data_mining/final_project/Code/source_code/PhoBERT/transformers\n",
            "time: 7.8 ms (started: 2023-06-06 07:25:58 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# !git clone https://github.com/VinAIResearch/PhoBERT\n",
        "%cd PhoBERT/\n",
        "# !git clone --single-branch --branch fast_tokenizers_BARTpho_PhoBERT_BERTweet https://github.com/datquocnguyen/transformers.git\n",
        "%cd transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nybCnC2ajEu1",
        "outputId": "7bfa4fa5-bb0d-4751-8c0b-fef208edfa53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/drive/.shortcut-targets-by-id/16CLBs4KTeHKahxECZFQFwRxk3_khT2VI/data_mining/final_project/Code/source_code/PhoBERT/transformers\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0.dev0) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0.dev0) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0.dev0) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0.dev0) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0.dev0) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0.dev0) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0.dev0) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0.dev0) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0.dev0) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0.dev0) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0.dev0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0.dev0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0.dev0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0.dev0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0.dev0) (3.4)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.28.0.dev0-py3-none-any.whl size=7134681 sha256=eb96dfcc03319b10b642de5965c68ac8cbe289751e65cb3812dfe759e343929f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-42_tuy4c/wheels/de/4d/7e/b2c81067b8a1b70134881385aa31827ccefd771de5f7138cf6\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.28.0.dev0\n",
            "    Uninstalling transformers-4.28.0.dev0:\n",
            "      Successfully uninstalled transformers-4.28.0.dev0\n",
            "Successfully installed transformers-4.28.0.dev0\n",
            "time: 1min 15s (started: 2023-06-06 07:25:58 +00:00)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7OjicGrjFz9",
        "outputId": "ae6f9410-02f7-4420-cced-4cfd9bd2b348"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.13.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.28.0.dev0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "time: 19.6 s (started: 2023-06-06 07:27:13 +00:00)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install tokenizers\n",
        "!pip install transformers"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "08H-eewFjSZ2"
      },
      "source": [
        "# Utils functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yQ8eQzojVP_",
        "outputId": "671b517f-211c-422b-cfb5-89cd94f42f98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 6.35 ms (started: 2023-06-06 07:27:33 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def add_condition_description(dataset):\n",
        "    # Additional conditions for better similarity among clusters involving subjects \n",
        "    conditions = {\n",
        "        'nganh_BB': 'Môn học bắt buộc',\n",
        "        'nganh_BMAV': 'Môn học ngoại ngữ',\n",
        "        'nganh_CNPM': 'Môn học thuộc khoa Công Nghệ Phần Mềm',\n",
        "        'nganh_HTTT': 'Môn học thuộc khoa Hệ Thống Thông Tin',\n",
        "        'nganh_KHMT': 'Môn học thuộc khoa Khoa Học Máy Tính',\n",
        "        'nganh_KTMT': 'Môn học thuộc khoa Kĩ Thuật Máy Tính',\n",
        "        'nganh_KTTT': 'Môn học thuộc khoa Kĩ Thuật Thông Tin',\n",
        "        'nganh_MMT&TT': 'Môn học thuộc khoa Mạng Máy Tính và Truyền Thông'\n",
        "    }\n",
        "    for condition, value in conditions.items():\n",
        "        mask = dataset[condition] == 1\n",
        "        dataset.loc[mask, 'monhoc_encode'] = dataset['tenmh'].astype(str) + ': ' + dataset['mota'].astype(str) + ' ' + value\n",
        "    return dataset\n",
        "    \n",
        "def filter(dataset, name_col: str, name_value: list):\n",
        "    data = dataset[dataset[name_col].isin(name_value)]\n",
        "    return data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "wucl1B57jX8n"
      },
      "source": [
        "# Load datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10mDwEBrjZ_4",
        "outputId": "a3618a44-5345-4d2b-dd0d-0870e7b43562"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['Unnamed: 0', 'mssv', 'gioitinh', 'CNPM', 'HTTT', 'KHMT', 'KTMT',\n",
            "       'KTTT', 'MMT&TT', 'CLC', 'CNTN', 'CQUI', 'CTTT', 'KSTN', 'nam_th',\n",
            "       'dien_tt', 'diem_tt', 'mamh', 'tenmh', 'mota', 'nganh_BB', 'nganh_BMAV',\n",
            "       'nganh_CNPM', 'nganh_HTTT', 'nganh_KHMT', 'nganh_KTMT', 'nganh_KTTT',\n",
            "       'nganh_MMT&TT', 'sotc', 'hocky', 'namhoc', 'diem_hp', 'trangthai',\n",
            "       'dtbhk', 'sotchk', 'drl', 'ghichu', 'dtb_toankhoa', 'dtb_tichluy',\n",
            "       'xeploai', 'dunghan'],\n",
            "      dtype='object')\n",
            "time: 4.24 s (started: 2023-06-06 07:27:33 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Load dataset\n",
        "dataset_original = pd.read_csv('../data/datasets.csv')\n",
        "print(dataset_original.columns)\n",
        "dataset_original_usage = dataset_original.copy()\n",
        "dataset_original = dataset_original[[        \\\n",
        "    'mssv', 'gioitinh', \n",
        "    'CNPM', 'HTTT', 'KHMT', 'KTMT', 'KTTT', 'MMT&TT',   \\\n",
        "    'CLC', 'CNTN', 'CQUI', 'CTTT', 'KSTN',  \\\n",
        "    'mamh', 'tenmh' ,'mota',    \\\n",
        "    'nganh_BB', 'nganh_BMAV', 'nganh_CNPM', 'nganh_HTTT', 'nganh_KHMT', 'nganh_KTMT', 'nganh_KTTT', 'nganh_MMT&TT',     \\\n",
        "    'diem_hp',      \\\n",
        "    'trangthai',        \\\n",
        "]]\n",
        "dataset_original = add_condition_description(dataset_original)\n",
        "dataset_original = dataset_original.drop_duplicates(subset=['mssv', 'mamh'], keep='last', inplace=False)\n",
        "dataset = dataset_original.drop(dataset_original[(dataset_original['nganh_BB'] == 1) | (dataset_original['nganh_BMAV'] == 1)].index)\n",
        "\n",
        "\n",
        "# Create 3 datasets\n",
        "scores = dataset[['mssv', 'mamh', 'diem_hp']].copy().drop_duplicates()\n",
        "subjects = dataset[['mamh', 'tenmh', 'monhoc_encode', \\\n",
        "                    'nganh_BB', 'nganh_BMAV', 'nganh_CNPM', 'nganh_HTTT', 'nganh_KHMT', 'nganh_KTMT', 'nganh_KTTT', 'nganh_MMT&TT']].copy().drop_duplicates()\n",
        "students = dataset[['mssv', 'gioitinh', \\\n",
        "                    'CNPM', 'HTTT', 'KHMT', 'KTMT', 'KTTT', 'MMT&TT', \\\n",
        "                    'CLC', 'CNTN', 'CQUI', 'CTTT', 'KSTN']].copy().drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pq-O9K_W2Wfr",
        "outputId": "cef927f5-4a6b-4df9-ec0a-b7a4a2387235"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at vinai/phobert-base-v2 were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at vinai/phobert-base-v2 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 16 s (started: 2023-06-06 07:27:37 +00:00)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "phobert = AutoModel.from_pretrained(\"vinai/phobert-base-v2\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base-v2\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VBkgROzvpVb9"
      },
      "source": [
        "### Get attention matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHDX-E6pjjSi",
        "outputId": "28f724f4-9981-455f-bde5-c18c10dedec0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 10.5 ms (started: 2023-06-06 07:27:53 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def get_attention_matrix(\n",
        "        dataset=None,\n",
        "        dataset_original=None,\n",
        "        phobert=None,\n",
        "        tokenizer=None):\n",
        "    # INPUT TEXT MUST BE ALREADY WORD-SEGMENTED!\n",
        "    monhoc = dict(zip(dataset['mamh'], dataset['monhoc_encode']))\n",
        "    lst_keys = list(monhoc.keys())\n",
        "    monhoc['PH001'] = 'Nhập môn điện tử: Đây là môn học ở giai đoan kiến thức đai cương. Môn học này trình bày các khái niệm và ̣phương pháp cơ bản về điện tử. Giới thiệu về nguyên lý hoạt động của của các linh kiện điện tử cơ bản (điện trở, tụ điện, nguồn điện, transistor,….). Ứng dụng các linh kiện điện tử này vào các mạch điện thực tế. Môn học thuộc khoa Kĩ Thuật Máy Tính'\n",
        "    # monhoc[lst_keys[19]] = 'Xác suất thống kê: Môn học này trình bày các khái niệm và phương pháp về: Lý thuyết xác suất (Không gian xác suất; Biến ngẫu nhiên; Hàm đặc trưng; Dãy các biến ngẫu nhiên; Các quy luật phân phối xác suất; Các định lý giới hạn phân phối xác suất) và Thống kê (Mẫu ngẫu nhiên; Ước lượng điểm và ước lượng khoảng; Kiểm định các giả thiết thống kê; Phân tích tương quan và hồi quy; Một số vấn đề về quá trình ngẫu nhiên). Ngoài ra, môn học này còn giới thiệu về cách thức nhận diện, phân tích và xử lý một vấn đề thực tế; xử lý các số liệu thống kê; để từ đó giúp cho người dùng đưa ra các suy luận phù hợp (nhằm hỗ trợ cho quá trình ra quyết định). Môn học bắt buộc'\n",
        "    monhoc['SE102'] = 'Nhập môn phát triển game: Kỹ thuật lập trình DirectX để xây dựng các game 2D đơn giản như Tetris, Battle City, Mario, Contras... Nội dung bao gồm: Giới thiệu ngành game, kỹ thuật lập trình Windows dùng C++ và Windows SDK, kỹ thuật làm chuyển động và lập trình DirectX cơ bản, kỹ thuật làm việc với Sprite và xử lý thiết bị nhập, thảo luận về các kỹ thuật hỗ trợ như phép biến đổi, lập trình DirectSound, hiển thị chữ ..., bàn luận về Game Engine và cách xây dựng một game engine đơn giản. Môn học thuộc khoa Công Nghệ Phần Mềm'\n",
        "    monhoc['SE101'] = 'Phương pháp mô hình hóa: Trình bày các kiến trúc, nền tảng về các phương pháp mô hình hóa thông tin, tri thức, biểu diễn vấn đề và lời giải, mô hình hóa hệ thống. Các phương pháp mô hình hóa và biểu diễn vấn đề như mô hình hóa và biểu diễn dữ liệu, mô hình hóa và biểu diễn quan hệ, mô hình hóa và biểu diễn tiến trình, mô hình hóa và biểu diễn tri thức (SDLC, JSD, SSM, OOA)... làm quen với các công cụ dùng để biểu diễn mô hình như công cụ CASE (upper và lower), các ngôn ngữ mô phỏng mô hình hóa như ngôn ngữ UML, VRML, ... nhằm hiện thực hóa một hệ thống. Học phần bao gồm dẫn nhập và giới thiệu những khái niệm về các mô hình đặc trung hiện nay; giới thiệu về phương pháp luận dùng cho mô hình hóa và giới thiệu cụ thể về các mô hình biểu diễn thông tin, dữ liệu, thời gian thực. Môn học thuộc khoa Công Nghệ Phần Mềm'\n",
        "    monhoc['NT118'] = 'Phát triển ứng dụng trên thiết bị di động: Thiết kế giao diện cho các thiết bị di động trên Google Android. Xây dựng ứng dụng Native app lẫn cross platform app. Trong ứng dụng native app, sử dụng Java để thể hiện chương trình trên Android; Trong ứng dụng Native app, sinh viên sử dụng HTML, CSS, JavaScript để tạo ra một ứng dụng chuyển tiếp, liên lạc và swipe, hình ảnh động. Tích hợp các dịch vụ web hiện có từ Google và Amazon. Các nội dung bao gồm: Giới thiệu về tính toán di động khắp mọi nơi, tính toán cảm ngữ cảnh, giới thiệu hệ điều hành Android và các phương pháp lập trình trên Android. Các phương pháp lập trình nâng cao: đa luồng, đa hành vi, kết nối SQLite, Web Services; Khái niệm cross platform, thiết kế web di động, ứng dụng cho Điện thoại di động. Đánh dấu cho điện thoại di động. Web Apps di động và tính năng. Giới thiệu PhoneGap. Bản địa hóa ứng dụng. Khoa Mạng Máy Tính và Truyền Thông'\n",
        "    monhoc['NT205'] = 'Tấn công mạng: Lý thuyết về những lỗ hổng bảo mật phổ biến tồn tại trong hệ thống mạng, hệ điều hành, ứng dụng; Các phương pháp tấn công dựa vào các lỗ hổng đã phát hiện; Các bước thực hiện tấn công chiếm quyền điều khiển hệ thống, thay đổi dữ liệu hay từ chối dịch vụ…; Xây dựng hệ thống phòng thủ ngăn chặn các cuộc tấn công. Đối với hệ Cử nhân tài năng: Trình bày chuyên sâu hơn về các giao thức mạng và việc tận dụng các lỗ hổng trong giao thức để tấn công; cách thức tấn công trên webserver cấu hình mạnh; các phương pháp tấn công ứng dụng web; cách thức tấn công và phòng chống lại các cuộc tấn công mạng trong tương lai; Bổ sung các bài tập nâng cao về việc sử dụng các công cụ crack password phức tạp và leo thang đặc quyền, xoá dấu vết, tấn công DDoS, cách thức điều khiển các zombie và xây dựng các mạng BotNet. Môn học thuộc khoa Mạng Máy Tính và Truyền Thông'\n",
        "    monhoc['SE334'] = 'Các phương pháp lập trình: Học phần này trình bày các kiến trúc, nền tảng về các phương pháp, kỹ thuật lập trình thường dùng khi thiết kế và xây dựng một chương trình máy tính. Ngôn ngữ C++, Java, các thư viện hỗ trợ trong lập trình song song. Học phần gồm: Giới thiệu các kỹ thuật và các nguyên lý cơ bản của lập trình; Giới thiệu cụ thể về các phương pháp và kỹ thuật lập trình như đệ qui, tối ưu mã chương trình, phương pháp lập trình cấu trúc, lập trình hướng đối tượng, lập trình đa nhiệm, song song; Giới thiệu kỹ thuật thiết kế kiến trúc và giao diện chương trình. Môn học thuộc khoa Công Nghệ Phần Mềm'\n",
        "    monhoc['NT505'] = 'Khóa luận tốt nghiệp: Một công trình nghiên cứu khoa học dành cho sinh viên. Trong khóa luận, sinh viên nêu rõ những vấn đề do sinh viên thực hiện được dưới sự hướng dẫn của giảng viên như: ứng dụng, quy trình hoạt động, hệ thống triển khai. Ngoài ra khóa luận cần có những đánh giá, phương hướng phát triển tiếp theo của đề tài. Trong khóa luận nêu rõ kết quả thực hiện của sinh viên, đây là thành phần quan trọng nhất của khóa luận. Đề tài khóa luận tốt nghiệp là một đề tài được nghiên cứu và triển khai chuyên sâu gắn với yêu cầu thực tế cho thấy khả năng nghiên cứu và làm việc độc lập của sinh viên. Trong khóa luận tốt nghiệp, cần xác định rõ những vấn đề do sinh viên thực hiện được dưới sự hướng dẫn của giảng viên như: ứng dụng, quy trình hoạt động, hệ thống triển khai, tính mới của nghiên cứu. Ngoài ra khóa luận cần có những đánh giá, phương hướng phát triển tiếp theo của đề tài. Trong khóa luận cần nêu rõ kết quả nghiên cứu của sinh viên. Môn học thuộc khoa Mạng Máy Tính và Truyền Thông'\n",
        "    monhoc['NT211'] = 'An ninh nhân sự, định danh và chứng thực: Khái niệm căn bản về định danh, xác thực và ứng dụng của chúng trong quản lý truy cập. Môn học trang bị cho sinh viên ngành an ninh thông tin: Khái niệm nền tảng về an ninh liên quan tới con người; Kiến thức về định danh cùng các công nghệ định danh hiện đại; Kiến thức về xác thực và những công nghệ liên quan đến xác thực; Ứng dụng định danh và xác thực trong hệ thống CNTT. Đối với hệ Cử nhân tài năng: Trình bày chuyên sâu hơn các nội dung Sinh trắc và các phương pháp chính; Quản lý tài khoản với Token; Quản lý tài khoản liên hợp; Tấn công thẻ thông minh; Bổ sung các bài tập nâng cao ở các nội dung trình bày chuyên sâu trên và các nội dung Bẻ mật khẩu phức tạp; Thiết kế, xây dựng và triển khai hệ thống cấp chứng chỉ số ở quy mô lớn. Môn học thuộc khoa Mạng Máy Tính và Truyền Thông'\n",
        "    monhoc['SE220'] = 'Thiết kế Game: Kiến thức, kỹ năng lĩnh vực thiết kế game. Lý thuyết về diễn biến tâm lý người chơi, bản chất của game, tại sao game hấp dẫn. Kỹ thuật thiết kế game, lịch sử trong thiết kế game. Tập trung vào thiết kế giao diện game như cách xây dựng menu, bố trí các thành phần giao diện, biểu tượng, thiết kế HUD. Bàn về thiết kế cảnh chơi như cách đặt thử thách, xây dựng bối cảnh, tạo hồn cho cảnh chơi... Môn học thuộc khoa Công Nghệ Phần Mềm'\n",
        "    monhoc['SE320'] = 'Lập trình đồ họa 3 chiều với Direct3D: Lập trình ứng dụng đồ họa 3 chiều và hướng dẫn sử dụng bộ thư viện đồ họa DirectX để xây dựng ứng dụng. Trình bày về cơ sở toán học ứng dụng trong đồ họa 3 chiều và quy trình dựng hình 3 chiều, trình bày về Direct3D bao gồm các vấn đề đi từ cơ bản đến nâng cao, ứng dụng các kiến thức đã học vào xây dựng trò chơi Tetris 3D. Kết thúc khóa học, sinh viên sẽ có khả năng tự thiết kế và lập trình ứng dụng đồ họa 3 chiều đơn giản trên môi trường Windows. Môn học thuộc khoa Công Nghệ Phần Mềm'\n",
        "    monhoc['NT534'] = 'An toàn mạng máy tính nâng cao: Cách phòng chống tấn công từ chối dịch vụ, các hoạt động ngầm trên Internet, bàn luận về các giải pháp kĩ thuật trong việc ngăn chặn cũng như đối phó với ngăn chặn trong việc quản lý truy cập trên Internet. Ngoài ra, môn này cũng đề cập các nguy cơ từ các loại mã độc tinh vi đối với an toàn mạng. Đối với hệ tài năng: Môn an toàn mạng đề cập các chủ đề căn bản của an toàn mạng. Môn này đề cập đến các vấn đề chuyên sâu hơn ví dụ như là làm thế nào để phòng chống tấn công từ chối dịch vụ, các hoạt động ngầm trên Internet, bàn luận về các giải pháp kĩ thuật trong việc ngăn chặn cũng như đối phó với ngăn chặn trong việc quản lý truy cập trên Internet. Ngoài ra, môn này cũng đề cập các nguy cơ từ các loại mã độc tinh vi đối với an toàn mạng. Cuối cùng, các kỹ thuật client side, server-side honeypot cũng được giới thiệu để nghiên cứu, thu thập mã độc. Môn học thuộc khoa Mạng Máy Tính và Truyền Thông'\n",
        "    monhoc['IE307'] = 'Công nghệ lập trình đa nền tảng cho ứng dụng di động: Môn học trình bày nguyên lý cơ bản của các Framework về lập trình di động đa nền tảng (React Native, PhoneGap, Xamarin...) và đặc biệt là Xamarin Framework. Cung cấp các Controls cơ bản của Xamarin, và áp dụng để xây dựng ứng dụng đa nền tảng: Label, Entry, Button, Image, Switch, ListView, DatePicker, TimePicker. Bên cạnh đó, môn học còn cung cấp thêm các vấn đề nâng cao của Xamarin, để tiếp tục tự nghiên cứu sử dụng về sau của Camera, Notification, Google Map APIs, Grial, RESTful API, Syncfusion... Môn học trang bị kỹ năng làm việc nhóm theo môi trường doanh nghiệp, đọc hiểu yêu cầu của khách hàng về ứng dụng di động, Phân tích & Thiết kế các ứng dụng di động để xây dựng một ứng dụng di động đa nền tảng cơ bản chạy trên iOS, Android & Windows Phone theo yêu cầu. Môn học thuộc khoa Kĩ Thuật Thông Tin'\n",
        "    lst_input_ids = [torch.tensor([tokenizer.encode(monhoc[key])]) for key in lst_keys]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        features = {}\n",
        "        for index, input_ids in enumerate(lst_input_ids):\n",
        "            features[lst_keys[index]] = phobert(input_ids).pooler_output\n",
        "\n",
        "    lst_supervision_extra_dic = {\n",
        "        'nganh_CNPM': 'Cung cấp sự hiểu biết các đặc trưng chính của phần mềm, khái niệm chu trình phần mềm, các hoạt động kỹ thuật, cung cấp kiến thức thực nghiệm về chọn lựa kỹ thuật, công cụ, mô hình chu trình dự án, các kiến thức độ quan trọng đảm bảo chất lượng (quality assurance), quản lý dự án trong phát triển phần mềm',\n",
        "        'nganh_HTTT': 'Nghiên cứu các hệ thống thông tin quản trị doanh nghiệp, ngân hàng như ERP, Supply Chain Management; Nghiên cứu các ứng dụng xây dựng hệ thống thông tin phục vụ Thương Mại Điện Tử; Phát triển các nghiên cứu nhằm tăng cường khai thác tri thức từ CSDL, quản trị các kho dữ liệu lớn, tìm kiếm thông tin trên web, tìm kiếm ngữ nghĩa, mạng xã hội; Phát triển các nghiên cứu liên ngành giữa tin học và các ngành khoa học khác như: xử lý ngôn ngữ tự nhiên, sinh học, hoá học, môi trường, ...',\n",
        "        'nganh_KHMT': 'Đào tạo bài bản về Trí tuệ nhân tạo (Artificial Intelligence - AI) đáp ứng nhu cầu về nghiên cứu, xây dựng và phát triển các sản phẩm, giải pháp thông minh phục vụ cho cuộc sống. Chương trình đào tạo của Khoa cung cấp cho sinh viên nhiều lựa chọn theo các định hướng nghề nghiệp như Trí tuệ Nhân tạo (AI), Thị giác Máy tính (Computer Vision), Xử lý Ngôn ngữ Tự nhiên (Natural Language Processing)…. Với các kiến thức nền tảng sinh viên hoàn toàn có thể tham gia nghiên cứu và phát triển các ứng dụng thông minh như: hệ thống nhận diện khuôn mặt (Face Recognition System), hệ thống Chatbot, hệ thống tìm kiếm – truy vấn thông tin (Retrieval System) ...',\n",
        "        'nganh_KTMT': 'Lập trình các phần mềm nhúng trên các thiết bị di động (Smartphone, Tablet, iphone, ipad, ...), các vi xử lý-vi điều khiển trong các hệ thống công nghiệp, xe ô tô, điện gia dụng, ngôi nhà thông minh,… (Chuyên ngành hệ thống nhúng và IoT); thiết kế mạch điện - điện tử, mạch điều khiển trong công nghiệp, vi mạch, chip,... (Chuyên ngành thiết kế vi mạch)',\n",
        "        'nganh_KTTT': 'Thiết kế, xây dựng và quản lý các dự án nghiên cứu và ứng dụng CNTT, chủ yếu trong lĩnh vực dữ liệu không gian-thời gian (địa lý, tài nguyên, môi trường, viễn thám. . .). Tập trung vào những ứng dụng về GIS trên thiết bị di động và trao đổi dữ liệu với máy chủ; Vận hành, quản lý, giám sát; phân tích và phát triển các ứng dụng CNTT tại các doanh nghiệp; Khai thác dữ liệu và thông tin ứng dụng cho các doanh nghiệp trong vấn đề phân tích định lượng; Xây dựng, phát triển các ứng dụng về lãnh vực truyền thông xã hội và công nghệ Web',\n",
        "        'nganh_MMT&TT': 'Quản trị mạng và hệ thống tại các ngân hàng, các trung tâm dữ liệu, các nhà cung cấp dịch vụ Internet (ISP); Thiết kế mạng chuyên nghiệp: xây dựng các mạng máy tính an toàn, hiệu quả cho các đơn vị có yêu cầu; Phát triển phần mềm mạng; Phát triển phần mềm mạng; Xây dựng và phát triển các ứng dụng truyền thông: VoIP, hội nghị truyền hình',\n",
        "    }\n",
        "    lst_supervision_keys = list(lst_supervision_extra_dic.keys())\n",
        "    lst_supervision_token = [torch.tensor([tokenizer.encode(lst_supervision_extra_dic[key])]) for key in ['nganh_CNPM', 'nganh_HTTT', 'nganh_KHMT', 'nganh_KTMT', 'nganh_KTTT', 'nganh_MMT&TT']]\n",
        "    with torch.no_grad():\n",
        "        features_supervision = {}\n",
        "        for index, input_ids in enumerate(lst_supervision_token):\n",
        "            features_supervision[lst_supervision_keys[index]] = phobert(input_ids).pooler_output\n",
        "\n",
        "    data_temp = dataset_original[['mamh', 'nganh_BB', 'nganh_BMAV', 'nganh_CNPM', 'nganh_HTTT', 'nganh_KHMT', 'nganh_KTMT', 'nganh_KTTT', 'nganh_MMT&TT']]\n",
        "\n",
        "    conditions = [\n",
        "        dataset_original['nganh_BB'] == 1,\n",
        "        dataset_original['nganh_BMAV'] == 1,\n",
        "        dataset_original['nganh_CNPM'] == 1,\n",
        "        dataset_original['nganh_HTTT'] == 1,\n",
        "        dataset_original['nganh_KHMT'] == 1,\n",
        "        dataset_original['nganh_KTMT'] == 1,\n",
        "        dataset_original['nganh_KTTT'] == 1,\n",
        "        dataset_original['nganh_MMT&TT'] == 1   \n",
        "    ]\n",
        "    values = ['nganh_BB', 'nganh_BMAV', 'nganh_CNPM', 'nganh_HTTT', 'nganh_KHMT', 'nganh_KTMT', 'nganh_KTTT', 'nganh_MMT&TT']\n",
        "    data_temp['nganh'] = np.select(conditions, values, default=0)\n",
        "\n",
        "    data_temp = data_temp.drop_duplicates()\n",
        "\n",
        "    for index, key in enumerate(features.keys()):\n",
        "        val = data_temp.loc[data_temp['mamh'] == key, 'nganh'].values[0]\n",
        "        if val in ['nganh_BB', 'nganh_BMAV']:\n",
        "            continue\n",
        "        else:\n",
        "            features[key] = torch.cat((features[key], features_supervision[val]), 1)\n",
        "    data = [{\n",
        "            'mh1': i, \n",
        "            'mh2': j, \n",
        "            'similarity': cosine_similarity(features[i], features[j]).item()\n",
        "        } \\\n",
        "        for i in features.keys() \\\n",
        "        for j in features.keys()]\n",
        "    attention_monhoc = pd.DataFrame(data)\n",
        "    attention_matrix = attention_monhoc.pivot_table(index=[\"mh1\"], columns=[\"mh2\"], values=\"similarity\")\n",
        "    # attention_matrix.to_csv('../../dataset/attention_matrix.csv')\n",
        "    return attention_matrix"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CLGFQ9KZpZW3"
      },
      "source": [
        "### Get related subjects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfRh6nU4lDSS",
        "outputId": "3b0edb7c-e300-488c-d4b4-d24637478f48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 1.12 ms (started: 2023-06-06 07:27:53 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Phase 1\n",
        "def get_related_subjects(\n",
        "        mamh_query=None, \n",
        "        attention_matrix=None, \n",
        "        k_threshold=20):\n",
        "    \n",
        "    si = attention_matrix[mamh_query]\n",
        "    rcm_df = pd.DataFrame(attention_matrix.corrwith(si).sort_values(ascending=False)).reset_index(drop=False)\n",
        "    rcm_df = rcm_df.rename(columns={rcm_df.columns[0]: 'mamh'})\n",
        "    related_subjects = rcm_df.head(k_threshold)['mamh'].tolist()\n",
        "    return related_subjects"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_4oLR-lVpc49"
      },
      "source": [
        "### Get related students"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNJYa_Knl9DU",
        "outputId": "ee9bc3e4-772b-4ac5-ab93-3808da7188cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 1.83 ms (started: 2023-06-06 07:27:53 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Phase 2\n",
        "def get_related_students(\n",
        "        dataset_original=None, \n",
        "        mamh_query=None, \n",
        "        mssv_query=None,\n",
        "        t_threshold=8):\n",
        "    \n",
        "    df_students = dataset_original[[\n",
        "        'mssv', 'gioitinh', \n",
        "        'CNPM', 'HTTT', 'KHMT', 'KTMT', 'KTTT', 'MMT&TT',   \\\n",
        "        'CLC', 'CNTN', 'CQUI', 'CTTT', 'KSTN',  \\\n",
        "        'mamh',     \\\n",
        "        'diem_hp',      \\\n",
        "    ]]\n",
        "    df_students = df_students[df_students['mamh'].isin(['IT001', 'IT002' ,'IT003', 'IT004', 'IT005', 'IT006', 'IT007'] + [mamh_query])]\n",
        "    one_hot_encoded = pd.pivot_table(data=df_students, index=df_students.index, columns='mamh', values='diem_hp', fill_value=-10.0)\n",
        "\n",
        "    # Concatenate the one-hot encoded columns with the original DataFrame\n",
        "    df_students_encoded = pd.concat([df_students, one_hot_encoded], axis=1)\n",
        "    df_students_merged = df_students_encoded.groupby('mssv').max().reset_index()\n",
        "    df_students_merged = df_students_merged.drop(columns=['mamh', 'diem_hp'])\n",
        "    \n",
        "    similarity_matrix = cosine_similarity(df_students_merged.iloc[:, 1:])\n",
        "    similarity_df = pd.DataFrame(similarity_matrix, index=df_students_merged['mssv'], columns=df_students_merged['mssv'])\n",
        "    float_list = np.arange(0.993, 0.998 + 0.0001, 0.0001).tolist()\n",
        "    for thr in float_list:\n",
        "        list_related_students = similarity_df[(similarity_df[mssv_query] > thr) & (similarity_df.index != mssv_query)].index\n",
        "        if len(list_related_students) != 0 and len(list_related_students) <= t_threshold:\n",
        "            break\n",
        "    return list_related_students"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1jqX4LpPpgZJ"
      },
      "source": [
        "### Get score single"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxT58fsElaxM",
        "outputId": "06031ed2-930b-432b-9993-ee733e705db3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 1.47 ms (started: 2023-06-06 07:27:53 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Phase calculate score\n",
        "def get_score_single(\n",
        "        dataset_original,\n",
        "        list_related_subjects=None,\n",
        "        list_related_students=None,\n",
        "        mamh_query=None,\n",
        "        mssv_query=None):\n",
        "    \n",
        "    if len(list_related_students) == 0:\n",
        "        return [], 0.0\n",
        "    for index, student in enumerate(list_related_students):\n",
        "        history_subjects = list(dataset_original[dataset_original['mssv'].isin([student])]['mamh'].unique())\n",
        "        if index == 0:\n",
        "            intersection = list(set(history_subjects) & set(list_related_subjects))\n",
        "        else:\n",
        "            intersection = list(set(history_subjects) & set(intersection))\n",
        "\n",
        "    intersection.remove(mamh_query)\n",
        "    if len(intersection) == 0:\n",
        "        return [], 0.0\n",
        "    sv_subjects = list(dataset_original[dataset_original['mssv'].isin([mssv_query])]['mamh'].unique())\n",
        "    result = list(set(sv_subjects) & set(intersection))\n",
        "    score_result = len(result) / len(intersection)\n",
        "    return (intersection, score_result)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "msfdrBSWpkto"
      },
      "source": [
        "# Inference 1 data point"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sE2Z5Im-pp5o",
        "outputId": "9372ca44-2dd3-4e2f-a87f-00d048c2f6f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 404 µs (started: 2023-06-06 07:27:53 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# ten_mh = 'CS112'\n",
        "# mssv = 'EAA0B693XPvAibaEXe99j2P15eeB04XwhZ0tzlI4'\n",
        "# attention_matrix = pd.read_csv('../../dataset/attention_matrix.csv')\n",
        "# ### Retrained entire to get Attention matrix, this progress take about 2, 3 minutes\n",
        "# attention_matrix = get_attention_matrix(\n",
        "#     dataset=dataset,\n",
        "#     dataset_original=dataset_original,\n",
        "#     phobert=phobert,\n",
        "#     tokenizer=tokenizer\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2R6RY3QNqeOQ",
        "outputId": "97ea6016-c184-4157-ffa1-9fee8fdde3b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 410 µs (started: 2023-06-06 07:27:53 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# from sklearn.metrics.pairwise import cosine_similarity\n",
        "# list_related_subjects = get_related_subjects(\n",
        "#     mamh_query=ten_mh, \n",
        "#     attention_matrix=attention_matrix,\n",
        "#     k_threshold=20)\n",
        "\n",
        "# list_related_students = get_related_students(\n",
        "#     dataset_original=dataset_original, \n",
        "#     mamh_query=ten_mh, \n",
        "#     mssv_query=mssv,\n",
        "#     t_threshold=0.995)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYvUxF-NokY0",
        "outputId": "7320f7d0-ef31-4814-e6df-38e626572832"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 439 µs (started: 2023-06-06 07:27:53 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# result = get_score_single(\n",
        "#     dataset_original=dataset_original,\n",
        "#     list_related_subjects=list_related_subjects,\n",
        "#     list_related_students=list_related_students,\n",
        "#     mamh_query=ten_mh,\n",
        "#     mssv_query=mssv)\n",
        "\n",
        "# result"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "06tLfZ9hwE38"
      },
      "source": [
        "# Training models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lW6Wp-TOwF1l"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "from tqdm import tqdm\n",
        "attention_matrix = pd.read_csv('../../dataset/attention_matrix.csv')\n",
        "i = 15\n",
        "while 15 <= i and i <= 22:\n",
        "    j = 3\n",
        "    while 3 <= j and j <= 10:\n",
        "        dataset_train = dataset_original.drop(dataset_original[(dataset_original['nganh_BB'] == 1) | (dataset_original['nganh_BMAV'] == 1)].index)\n",
        "        lst_users = list(dataset_train['mssv'].unique())\n",
        "        score = 0.0\n",
        "        lst_count = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "        print(f'\\nthreshold_get_subjects: {i}, threshold_get_students: {j}')\n",
        "\n",
        "        for index_user, user in tqdm(enumerate(lst_users)):\n",
        "\n",
        "            if index_user == 5:\n",
        "                break\n",
        "\n",
        "            data_user = filter(dataset_train, 'mssv', [user])\n",
        "            data_user.drop_duplicates(subset=['mssv', 'mamh'], keep='last', inplace=False)\n",
        "\n",
        "            lst_user_mamh = list(data_user['mamh'])\n",
        "            # print(f'\\nUser: {index_user+1} with the number of subjects: {len(lst_user_mamh)} -------------')\n",
        "            result_user_single = 0.0\n",
        "            for index, user_mamh in enumerate(lst_user_mamh):\n",
        "                list_related_subjects = get_related_subjects(\n",
        "                    mamh_query=user_mamh, \n",
        "                    attention_matrix=attention_matrix,\n",
        "                    k_threshold=i)\n",
        "                \n",
        "                list_related_students = get_related_students(\n",
        "                    dataset_original=dataset_original, \n",
        "                    mamh_query=user_mamh, \n",
        "                    mssv_query=user,\n",
        "                    t_threshold=j)\n",
        "                \n",
        "                list_result, result = get_score_single(\n",
        "                    dataset_original=dataset_original,\n",
        "                    list_related_subjects=list_related_subjects,\n",
        "                    list_related_students=list_related_students,\n",
        "                    mamh_query=user_mamh,\n",
        "                    mssv_query=user)\n",
        "                # print(f'\\nUser: {user} ------ Subject: {user_mamh} ------ list: {list_result} ------ Score = {round(result, 2)}')\n",
        "                if len(list_result) <= 7:\n",
        "                    lst_count[len(list_result)] += 1\n",
        "                else:\n",
        "                    lst_count[-1] += 1\n",
        "\n",
        "                result_user_single += result\n",
        "            # print(f'Total loss single for {user}: {result_user_single / len(lst_user_mamh)}')\n",
        "            # print(f'\\n================================================================================\\n')\n",
        "            \n",
        "            score += (result_user_single / (index + 1))\n",
        "\n",
        "        print(f'Total score: {score * 100 / (index_user + 1)}')\n",
        "        print(f'Count: {lst_count}')\n",
        "\n",
        "        with open('../../example.txt', 'a') as file:\n",
        "            file.write(f'threshold_get_subjects: {i}, threshold_get_students: {j}, score: {score * 100 / 5}, count: {lst_count}\\n')\n",
        "\n",
        "        j += 1\n",
        "    i += 1"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lix9ycROjVer"
      },
      "source": [
        "### Add data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVJXfQ5qjU-b",
        "outputId": "29369220-8dd2-4291-e5de-da2c6d8642ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 1.3 ms (started: 2023-06-06 07:28:38 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def input_prediction(\n",
        "    _mssv = None,\n",
        "    _gioitinh = None,\n",
        "    _khoa = None,\n",
        "    _hedaotao = None,\n",
        "    _mamh = None,\n",
        "    _ten_mh = None,\n",
        "    _diem_hp = None,\n",
        "):\n",
        "    new_data_point = {\n",
        "        'mssv': _mssv,\n",
        "        'gioitinh': 1 if _gioitinh == 'Nam' else 0,\n",
        "        # khoa\n",
        "        'CNPM': 1 if _khoa == 'CNPM' else 0,\n",
        "        'HTTT': 1 if _khoa == 'HTTT' else 0,\n",
        "        'KHMT': 1 if _khoa == 'KHMT' else 0,\n",
        "        'KTMT': 1 if _khoa == 'KTMT' else 0,\n",
        "        'KTTT': 1 if _khoa == 'KTTT' else 0,\n",
        "        'MMT&TT': 1 if _khoa == 'MMT&TT' else 0,\n",
        "\n",
        "        # he dao tao\n",
        "        'CLC': 1 if _hedaotao == 'CLC' else 0,\n",
        "        'CNTN': 1 if _hedaotao == 'CNTN' else 0,\n",
        "        'CQUI': 1 if _hedaotao == 'CQUI' else 0,\n",
        "        'CTTT': 1 if _hedaotao == 'CTTT' else 0,\n",
        "        'KSTN': 1 if _hedaotao == 'KSTN' else 0,\n",
        "\n",
        "        # diem hoc phan\n",
        "        'diem_hp': _diem_hp,\n",
        "    }\n",
        "\n",
        "    # new_data_point\n",
        "    return new_data_point"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2u-eH8Rm8Kd",
        "outputId": "eb54ca02-dfe1-4367-c185-b60e52812174"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 35.5 ms (started: 2023-06-06 07:37:03 +00:00)\n"
          ]
        }
      ],
      "source": [
        "dataset_original = dataset_original.append([\n",
        "    input_prediction(_mssv = '20521494', _gioitinh = 'Nam', _khoa = 'KHMT', _hedaotao = 'CQUI', _mamh = 'IT001', _diem_hp = 8.1,),\n",
        "    input_prediction(_mssv = '20521494', _gioitinh = 'Nam', _khoa = 'KHMT', _hedaotao = 'CQUI', _mamh = 'IT002', _diem_hp = 8.5,),\n",
        "    input_prediction(_mssv = '20521494', _gioitinh = 'Nam', _khoa = 'KHMT', _hedaotao = 'CQUI', _mamh = 'IT003', _diem_hp = 9.4,),\n",
        "    input_prediction(_mssv = '20521494', _gioitinh = 'Nam', _khoa = 'KHMT', _hedaotao = 'CQUI', _mamh = 'IT004', _diem_hp = 7.7,),\n",
        "    input_prediction(_mssv = '20521494', _gioitinh = 'Nam', _khoa = 'KHMT', _hedaotao = 'CQUI', _mamh = 'IT005', _diem_hp = 8.1,),\n",
        "    input_prediction(_mssv = '20521494', _gioitinh = 'Nam', _khoa = 'KHMT', _hedaotao = 'CQUI', _mamh = 'IT006', _diem_hp = -10.0,),\n",
        "    input_prediction(_mssv = '20521494', _gioitinh = 'Nam', _khoa = 'KHMT', _hedaotao = 'CQUI', _mamh = 'IT007', _diem_hp = 9.3,),\n",
        "], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-RJYf9Vt6C5",
        "outputId": "4c7b83ec-b913-4eca-ea8d-edef00164553"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'datetime.datetime'>\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# Get the current time\n",
        "current_time = datetime.now()\n",
        "\n",
        "# Print the current time\n",
        "print(type(current_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZCiNcNBt6iX",
        "outputId": "996992e4-344d-43ff-f51e-7059c711bba3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-06-07 00:19:57.909699+07:00\n",
            "2023 6 7 0 19 57 909699\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "import pytz\n",
        "\n",
        "# Set the desired timezone (Vietnam)\n",
        "timezone = pytz.timezone('Asia/Ho_Chi_Minh')\n",
        "\n",
        "# Get the current time in Vietnam\n",
        "current_time = datetime.now(timezone)\n",
        "\n",
        "# Print the current time\n",
        "print(current_time)\n",
        "year = current_time.year\n",
        "month = current_time.month\n",
        "day = current_time.day\n",
        "hour = current_time.hour\n",
        "minute = current_time.minute\n",
        "second = current_time.second\n",
        "microsecond = current_time.microsecond\n",
        "\n",
        "print(year, month, day, hour, minute, second, microsecond)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "NKTMNa12_Sm7"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
