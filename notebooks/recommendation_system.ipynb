{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xRCyaQP3wmpK"
      },
      "source": [
        "# Work space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLjWnDAZwRpb",
        "outputId": "bc5dbdf2-fbc7-4841-9fb2-12d1cc397cc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ipython-autotime in /usr/local/lib/python3.10/dist-packages (0.3.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from ipython-autotime) (7.34.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (67.7.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.18.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (3.0.38)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (2.14.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->ipython-autotime) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->ipython-autotime) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ipython-autotime) (0.2.6)\n",
            "time: 481 Âµs (started: 2023-06-06 07:25:51 +00:00)\n"
          ]
        }
      ],
      "source": [
        "!pip install ipython-autotime\n",
        "%load_ext autotime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJIu9I8zknsQ",
        "outputId": "27445b16-5c7d-4812-b61a-1f05db288419"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/.shortcut-targets-by-id/16CLBs4KTeHKahxECZFQFwRxk3_khT2VI/data_mining/final_project/Code/source_code\n",
            "\u001b[0m\u001b[01;34mdataset\u001b[0m/                      recommendation_thien_2.ipynb  \u001b[01;34mresults\u001b[0m/\n",
            "\u001b[01;34mPhoBERT\u001b[0m/                      recommendation_thien_3.ipynb  Thien.ipynb\n",
            "recommendation_kiet.ipynb     recommendation_thien.ipynb\n",
            "recommendation_thien_1.ipynb  recommendation_v1.ipynb\n",
            "time: 6.47 s (started: 2023-06-06 07:25:51 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Import nessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# import country_converter as coco\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-JOssHW1i-p1"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmHg-eunjDRL",
        "outputId": "1f67d39b-31dc-4fb9-a9cc-14fcc05181d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/16CLBs4KTeHKahxECZFQFwRxk3_khT2VI/data_mining/final_project/Code/source_code/PhoBERT\n",
            "/content/drive/.shortcut-targets-by-id/16CLBs4KTeHKahxECZFQFwRxk3_khT2VI/data_mining/final_project/Code/source_code/PhoBERT/transformers\n",
            "time: 7.8 ms (started: 2023-06-06 07:25:58 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# !git clone https://github.com/VinAIResearch/PhoBERT\n",
        "%cd PhoBERT/\n",
        "# !git clone --single-branch --branch fast_tokenizers_BARTpho_PhoBERT_BERTweet https://github.com/datquocnguyen/transformers.git\n",
        "%cd transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nybCnC2ajEu1",
        "outputId": "7bfa4fa5-bb0d-4751-8c0b-fef208edfa53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/drive/.shortcut-targets-by-id/16CLBs4KTeHKahxECZFQFwRxk3_khT2VI/data_mining/final_project/Code/source_code/PhoBERT/transformers\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0.dev0) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0.dev0) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0.dev0) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0.dev0) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0.dev0) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0.dev0) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0.dev0) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0.dev0) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0.dev0) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0.dev0) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0.dev0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0.dev0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0.dev0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0.dev0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0.dev0) (3.4)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.28.0.dev0-py3-none-any.whl size=7134681 sha256=eb96dfcc03319b10b642de5965c68ac8cbe289751e65cb3812dfe759e343929f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-42_tuy4c/wheels/de/4d/7e/b2c81067b8a1b70134881385aa31827ccefd771de5f7138cf6\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.28.0.dev0\n",
            "    Uninstalling transformers-4.28.0.dev0:\n",
            "      Successfully uninstalled transformers-4.28.0.dev0\n",
            "Successfully installed transformers-4.28.0.dev0\n",
            "time: 1min 15s (started: 2023-06-06 07:25:58 +00:00)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7OjicGrjFz9",
        "outputId": "ae6f9410-02f7-4420-cced-4cfd9bd2b348"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.13.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.28.0.dev0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "time: 19.6 s (started: 2023-06-06 07:27:13 +00:00)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install tokenizers\n",
        "!pip install transformers"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "08H-eewFjSZ2"
      },
      "source": [
        "# Utils functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yQ8eQzojVP_",
        "outputId": "671b517f-211c-422b-cfb5-89cd94f42f98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 6.35 ms (started: 2023-06-06 07:27:33 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def add_condition_description(dataset):\n",
        "    # Additional conditions for better similarity among clusters involving subjects \n",
        "    conditions = {\n",
        "        'nganh_BB': 'MÃ´n há»c báº¯t buá»c',\n",
        "        'nganh_BMAV': 'MÃ´n há»c ngoáº¡i ngá»¯',\n",
        "        'nganh_CNPM': 'MÃ´n há»c thuá»c khoa CÃ´ng Nghá» Pháº§n Má»m',\n",
        "        'nganh_HTTT': 'MÃ´n há»c thuá»c khoa Há» Thá»ng ThÃ´ng Tin',\n",
        "        'nganh_KHMT': 'MÃ´n há»c thuá»c khoa Khoa Há»c MÃ¡y TÃ­nh',\n",
        "        'nganh_KTMT': 'MÃ´n há»c thuá»c khoa KÄ© Thuáº­t MÃ¡y TÃ­nh',\n",
        "        'nganh_KTTT': 'MÃ´n há»c thuá»c khoa KÄ© Thuáº­t ThÃ´ng Tin',\n",
        "        'nganh_MMT&TT': 'MÃ´n há»c thuá»c khoa Máº¡ng MÃ¡y TÃ­nh vÃ  Truyá»n ThÃ´ng'\n",
        "    }\n",
        "    for condition, value in conditions.items():\n",
        "        mask = dataset[condition] == 1\n",
        "        dataset.loc[mask, 'monhoc_encode'] = dataset['tenmh'].astype(str) + ': ' + dataset['mota'].astype(str) + ' ' + value\n",
        "    return dataset\n",
        "    \n",
        "def filter(dataset, name_col: str, name_value: list):\n",
        "    data = dataset[dataset[name_col].isin(name_value)]\n",
        "    return data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "wucl1B57jX8n"
      },
      "source": [
        "# Load datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10mDwEBrjZ_4",
        "outputId": "a3618a44-5345-4d2b-dd0d-0870e7b43562"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['Unnamed: 0', 'mssv', 'gioitinh', 'CNPM', 'HTTT', 'KHMT', 'KTMT',\n",
            "       'KTTT', 'MMT&TT', 'CLC', 'CNTN', 'CQUI', 'CTTT', 'KSTN', 'nam_th',\n",
            "       'dien_tt', 'diem_tt', 'mamh', 'tenmh', 'mota', 'nganh_BB', 'nganh_BMAV',\n",
            "       'nganh_CNPM', 'nganh_HTTT', 'nganh_KHMT', 'nganh_KTMT', 'nganh_KTTT',\n",
            "       'nganh_MMT&TT', 'sotc', 'hocky', 'namhoc', 'diem_hp', 'trangthai',\n",
            "       'dtbhk', 'sotchk', 'drl', 'ghichu', 'dtb_toankhoa', 'dtb_tichluy',\n",
            "       'xeploai', 'dunghan'],\n",
            "      dtype='object')\n",
            "time: 4.24 s (started: 2023-06-06 07:27:33 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Load dataset\n",
        "dataset_original = pd.read_csv('../data/datasets.csv')\n",
        "print(dataset_original.columns)\n",
        "dataset_original_usage = dataset_original.copy()\n",
        "dataset_original = dataset_original[[        \\\n",
        "    'mssv', 'gioitinh', \n",
        "    'CNPM', 'HTTT', 'KHMT', 'KTMT', 'KTTT', 'MMT&TT',   \\\n",
        "    'CLC', 'CNTN', 'CQUI', 'CTTT', 'KSTN',  \\\n",
        "    'mamh', 'tenmh' ,'mota',    \\\n",
        "    'nganh_BB', 'nganh_BMAV', 'nganh_CNPM', 'nganh_HTTT', 'nganh_KHMT', 'nganh_KTMT', 'nganh_KTTT', 'nganh_MMT&TT',     \\\n",
        "    'diem_hp',      \\\n",
        "    'trangthai',        \\\n",
        "]]\n",
        "dataset_original = add_condition_description(dataset_original)\n",
        "dataset_original = dataset_original.drop_duplicates(subset=['mssv', 'mamh'], keep='last', inplace=False)\n",
        "dataset = dataset_original.drop(dataset_original[(dataset_original['nganh_BB'] == 1) | (dataset_original['nganh_BMAV'] == 1)].index)\n",
        "\n",
        "\n",
        "# Create 3 datasets\n",
        "scores = dataset[['mssv', 'mamh', 'diem_hp']].copy().drop_duplicates()\n",
        "subjects = dataset[['mamh', 'tenmh', 'monhoc_encode', \\\n",
        "                    'nganh_BB', 'nganh_BMAV', 'nganh_CNPM', 'nganh_HTTT', 'nganh_KHMT', 'nganh_KTMT', 'nganh_KTTT', 'nganh_MMT&TT']].copy().drop_duplicates()\n",
        "students = dataset[['mssv', 'gioitinh', \\\n",
        "                    'CNPM', 'HTTT', 'KHMT', 'KTMT', 'KTTT', 'MMT&TT', \\\n",
        "                    'CLC', 'CNTN', 'CQUI', 'CTTT', 'KSTN']].copy().drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pq-O9K_W2Wfr",
        "outputId": "cef927f5-4a6b-4df9-ec0a-b7a4a2387235"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at vinai/phobert-base-v2 were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at vinai/phobert-base-v2 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 16 s (started: 2023-06-06 07:27:37 +00:00)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "phobert = AutoModel.from_pretrained(\"vinai/phobert-base-v2\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base-v2\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VBkgROzvpVb9"
      },
      "source": [
        "### Get attention matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHDX-E6pjjSi",
        "outputId": "28f724f4-9981-455f-bde5-c18c10dedec0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 10.5 ms (started: 2023-06-06 07:27:53 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def get_attention_matrix(\n",
        "        dataset=None,\n",
        "        dataset_original=None,\n",
        "        phobert=None,\n",
        "        tokenizer=None):\n",
        "    # INPUT TEXT MUST BE ALREADY WORD-SEGMENTED!\n",
        "    monhoc = dict(zip(dataset['mamh'], dataset['monhoc_encode']))\n",
        "    lst_keys = list(monhoc.keys())\n",
        "    monhoc['PH001'] = 'Nháº­p mÃ´n Äiá»n tá»­: ÄÃ¢y laÌ mÃ´n há»c Æ¡Ì giai Äoan kiáº¿n thÆ°Ìc Äai cÆ°Æ¡ng. MÃ´n há»c nÃ y trÃ¬nh bÃ y cÃ¡c khÃ¡i niá»m vÃ  Ì£phÆ°Æ¡ng phÃ¡p cÆ¡ báº£n vá» Äiá»n tá»­. Giá»i thiá»u vá» nguyÃªn lÃ½ hoáº¡t Äá»ng cá»§a cá»§a cÃ¡c linh kiá»n Äiá»n tá»­ cÆ¡ báº£n (Äiá»n trá», tá»¥ Äiá»n, nguá»n Äiá»n, transistor,â¦.). á»¨ng dá»¥ng cÃ¡c linh kiá»n Äiá»n tá»­ nÃ y vÃ o cÃ¡c máº¡ch Äiá»n thá»±c táº¿. MÃ´n há»c thuá»c khoa KÄ© Thuáº­t MÃ¡y TÃ­nh'\n",
        "    # monhoc[lst_keys[19]] = 'XÃ¡c suáº¥t thá»ng kÃª: MÃ´n hoÌ£c naÌy triÌnh baÌy caÌc khaÌi niÃªÌ£m vaÌ phÆ°Æ¡ng phaÌp vÃªÌ: LÃ½ thuyáº¿t xÃ¡c suáº¥t (KhÃ´ng gian xÃ¡c suáº¥t; Biáº¿n ngáº«u nhiÃªn; HÃ m Äáº·c trÆ°ng; DÃ£y cÃ¡c biáº¿n ngáº«u nhiÃªn; CÃ¡c quy luáº­t phÃ¢n phá»i xÃ¡c suáº¥t; CÃ¡c Äá»nh lÃ½ giá»i háº¡n phÃ¢n phá»i xÃ¡c suáº¥t) vaÌ Thá»ng kÃª (Máº«u ngáº«u nhiÃªn; Æ¯á»c lÆ°á»£ng Äiá»m vÃ  Æ°á»c lÆ°á»£ng khoáº£ng; Kiá»m Äá»nh cÃ¡c giáº£ thiáº¿t thá»ng kÃª; PhÃ¢n tÃ­ch tÆ°Æ¡ng quan vÃ  há»i quy; Má»t sá» váº¥n Äá» vá» quÃ¡ trÃ¬nh ngáº«u nhiÃªn). NgoaÌi ra, mÃ´n hoÌ£c naÌy coÌn giá»i thiá»u vá» cÃ¡ch thá»©c nháº­n diá»n, phÃ¢n tÃ­ch vÃ  xá»­ lÃ½ má»t váº¥n Äá» thá»±c táº¿; xá»­ lÃ½ cÃ¡c sá» liá»u thá»ng kÃª; Äá» tá»« ÄÃ³ giuÌp cho ngÆ°Æ¡Ìi duÌng ÄÆ°a ra cÃ¡c suy luáº­n phÃ¹ há»£p (nháº±m há» trá»£ cho quÃ¡ trÃ¬nh ra quyáº¿t Äá»nh). MÃ´n há»c báº¯t buá»c'\n",
        "    monhoc['SE102'] = 'Nháº­p mÃ´n phÃ¡t triá»n game: KyÌ thuÃ¢Ì£t lÃ¢Ì£p triÌnh DirectX ÄÃªÌ xÃ¢y dÆ°Ì£ng caÌc game 2D ÄÆ¡n giaÌn nhÆ° Tetris, Battle City, Mario, Contras... Ná»i dung bao gá»m: GiÆ¡Ìi thiÃªÌ£u ngaÌnh game, kyÌ thuÃ¢Ì£t lÃ¢Ì£p triÌnh Windows duÌng C++ vaÌ Windows SDK, kyÌ thuÃ¢Ì£t laÌm chuyÃªÌn ÄÃ´Ì£ng vaÌ lÃ¢Ì£p triÌnh DirectX cÆ¡ baÌn, kyÌ thuÃ¢Ì£t laÌm viÃªÌ£c vÆ¡Ìi Sprite vaÌ xÆ°Ì lyÌ thiÃªÌt biÌ£ nhÃ¢Ì£p, thaÌo luÃ¢Ì£n vÃªÌ caÌc kyÌ thuÃ¢Ì£t hÃ´Ì trÆ¡Ì£ nhÆ° pheÌp biÃªÌn ÄÃ´Ìi, lÃ¢Ì£p triÌnh DirectSound, hiÃªÌn thiÌ£ chÆ°Ì ..., baÌn luÃ¢Ì£n vÃªÌ Game Engine vaÌ caÌch xÃ¢y dÆ°Ì£ng mÃ´Ì£t game engine ÄÆ¡n giaÌn. MÃ´n há»c thuá»c khoa CÃ´ng Nghá» Pháº§n Má»m'\n",
        "    monhoc['SE101'] = 'PhÆ°Æ¡ng phÃ¡p mÃ´ hÃ¬nh hÃ³a: TrÃ¬nh bÃ y cÃ¡c kiáº¿n trÃºc, ná»n táº£ng vá» cÃ¡c phÆ°Æ¡ng phÃ¡p mÃ´ hÃ¬nh hÃ³a thÃ´ng tin, tri thá»©c, biá»u diá»n váº¥n Äá» vÃ  lá»i giáº£i, mÃ´ hÃ¬nh hÃ³a há» thá»ng. CÃ¡c phÆ°Æ¡ng phÃ¡p mÃ´ hÃ¬nh hÃ³a vÃ  biá»u diá»n váº¥n Äá» nhÆ° mÃ´ hÃ¬nh hÃ³a vÃ  biá»u diá»n dá»¯ liá»u, mÃ´ hÃ¬nh hÃ³a vÃ  biá»u diá»n quan há», mÃ´ hÃ¬nh hÃ³a vÃ  biá»u diá»n tiáº¿n trÃ¬nh, mÃ´ hÃ¬nh hÃ³a vÃ  biá»u diá»n tri thá»©c (SDLC, JSD, SSM, OOA)... lÃ m quen vá»i cÃ¡c cÃ´ng cá»¥ dÃ¹ng Äá» biá»u diá»n mÃ´ hÃ¬nh nhÆ° cÃ´ng cá»¥ CASE (upper vÃ  lower), cÃ¡c ngÃ´n ngá»¯ mÃ´ phá»ng mÃ´ hÃ¬nh hÃ³a nhÆ° ngÃ´n ngá»¯ UML, VRML, ... nháº±m hiá»n thá»±c hÃ³a má»t há» thá»ng. Há»c pháº§n bao gá»m dáº«n nháº­p vÃ  giá»i thiá»u nhá»¯ng khÃ¡i niá»m vá» cÃ¡c mÃ´ hÃ¬nh Äáº·c trung hiá»n nay; giá»i thiá»u vá» phÆ°Æ¡ng phÃ¡p luáº­n dÃ¹ng cho mÃ´ hÃ¬nh hÃ³a vÃ  giá»i thiá»u cá»¥ thá» vá» cÃ¡c mÃ´ hÃ¬nh biá»u diá»n thÃ´ng tin, dá»¯ liá»u, thá»i gian thá»±c. MÃ´n há»c thuá»c khoa CÃ´ng Nghá» Pháº§n Má»m'\n",
        "    monhoc['NT118'] = 'PhÃ¡t triá»n á»©ng dá»¥ng trÃªn thiáº¿t bá» di Äá»ng: Thiáº¿t káº¿ giao diá»n cho cÃ¡c thiáº¿t bá» di Äá»ng trÃªn Google Android. XÃ¢y dá»±ng á»©ng dá»¥ng Native app láº«n cross platform app. Trong á»©ng dá»¥ng native app, sá»­ dá»¥ng Java Äá» thá» hiá»n chÆ°Æ¡ng trÃ¬nh trÃªn Android; Trong á»©ng dá»¥ng Native app, sinh viÃªn sá»­ dá»¥ng HTML, CSS, JavaScript Äá» táº¡o ra má»t á»©ng dá»¥ng chuyá»n tiáº¿p, liÃªn láº¡c vÃ  swipe, hÃ¬nh áº£nh Äá»ng. TÃ­ch há»£p cÃ¡c dá»ch vá»¥ web hiá»n cÃ³ tá»« Google vÃ  Amazon. CÃ¡c ná»i dung bao gá»m: Giá»i thiá»u vá» tÃ­nh toÃ¡n di Äá»ng kháº¯p má»i nÆ¡i, tÃ­nh toÃ¡n cáº£m ngá»¯ cáº£nh, giá»i thiá»u há» Äiá»u hÃ nh Android vÃ  cÃ¡c phÆ°Æ¡ng phÃ¡p láº­p trÃ¬nh trÃªn Android. CÃ¡c phÆ°Æ¡ng phÃ¡p láº­p trÃ¬nh nÃ¢ng cao: Äa luá»ng, Äa hÃ nh vi, káº¿t ná»i SQLite, Web Services; KhÃ¡i niá»m cross platform, thiáº¿t káº¿ web di Äá»ng, á»©ng dá»¥ng cho Äiá»n thoáº¡i di Äá»ng. ÄÃ¡nh dáº¥u cho Äiá»n thoáº¡i di Äá»ng. Web Apps di Äá»ng vÃ  tÃ­nh nÄng. Giá»i thiá»u PhoneGap. Báº£n Äá»a hÃ³a á»©ng dá»¥ng. Khoa Máº¡ng MÃ¡y TÃ­nh vÃ  Truyá»n ThÃ´ng'\n",
        "    monhoc['NT205'] = 'Táº¥n cÃ´ng máº¡ng: LÃ½ thuyáº¿t vá» nhá»¯ng lá» há»ng báº£o máº­t phá» biáº¿n tá»n táº¡i trong há» thá»ng máº¡ng, há» Äiá»u hÃ nh, á»©ng dá»¥ng; CÃ¡c phÆ°Æ¡ng phÃ¡p táº¥n cÃ´ng dá»±a vÃ o cÃ¡c lá» há»ng ÄÃ£ phÃ¡t hiá»n; CÃ¡c bÆ°á»c thá»±c hiá»n táº¥n cÃ´ng chiáº¿m quyá»n Äiá»u khiá»n há» thá»ng, thay Äá»i dá»¯ liá»u hay tá»« chá»i dá»ch vá»¥â¦; XÃ¢y dá»±ng há» thá»ng phÃ²ng thá»§ ngÄn cháº·n cÃ¡c cuá»c táº¥n cÃ´ng. Äá»i vá»i há» Cá»­ nhÃ¢n tÃ i nÄng: TrÃ¬nh bÃ y chuyÃªn sÃ¢u hÆ¡n vá» cÃ¡c giao thá»©c máº¡ng vÃ  viá»c táº­n dá»¥ng cÃ¡c lá» há»ng trong giao thá»©c Äá» táº¥n cÃ´ng; cÃ¡ch thá»©c táº¥n cÃ´ng trÃªn webserver cáº¥u hÃ¬nh máº¡nh; cÃ¡c phÆ°Æ¡ng phÃ¡p táº¥n cÃ´ng á»©ng dá»¥ng web; cÃ¡ch thá»©c táº¥n cÃ´ng vÃ  phÃ²ng chá»ng láº¡i cÃ¡c cuá»c táº¥n cÃ´ng máº¡ng trong tÆ°Æ¡ng lai; Bá» sung cÃ¡c bÃ i táº­p nÃ¢ng cao vá» viá»c sá»­ dá»¥ng cÃ¡c cÃ´ng cá»¥ crack password phá»©c táº¡p vÃ  leo thang Äáº·c quyá»n, xoÃ¡ dáº¥u váº¿t, táº¥n cÃ´ng DDoS, cÃ¡ch thá»©c Äiá»u khiá»n cÃ¡c zombie vÃ  xÃ¢y dá»±ng cÃ¡c máº¡ng BotNet. MÃ´n há»c thuá»c khoa Máº¡ng MÃ¡y TÃ­nh vÃ  Truyá»n ThÃ´ng'\n",
        "    monhoc['SE334'] = 'CÃ¡c phÆ°Æ¡ng phÃ¡p láº­p trÃ¬nh: Há»c pháº§n nÃ y trÃ¬nh bÃ y cÃ¡c kiáº¿n trÃºc, ná»n táº£ng vá» cÃ¡c phÆ°Æ¡ng phÃ¡p, kyÌ thuÃ¢Ì£t lÃ¢Ì£p triÌnh thÆ°á»ng dÃ¹ng khi thiáº¿t káº¿ vÃ  xÃ¢y dá»±ng má»t chÆ°Æ¡ng trÃ¬nh mÃ¡y tÃ­nh. NgÃ´n ngÆ°Ì C++, Java, caÌc thÆ° viÃªÌ£n hÃ´Ì trÆ¡Ì£ trong lÃ¢Ì£p triÌnh song song. Há»c pháº§n gá»m: GiÆ¡Ìi thiÃªÌ£u caÌc kyÌ thuÃ¢Ì£t vaÌ caÌc nguyÃªn lyÌ cÆ¡ baÌn cuÌa lÃ¢Ì£p triÌnh; Giá»i thiá»u cuÌ£ thÃªÌ vÃªÌ caÌc phÆ°Æ¡ng phaÌp vaÌ kyÌ thuÃ¢Ì£t lÃ¢Ì£p triÌnh nhÆ° ÄÃªÌ£ qui, tá»i Æ°u mÃ£ chÆ°Æ¡ng trÃ¬nh, phÆ°Æ¡ng phÃ¡p lÃ¢Ì£p triÌnh cÃ¢Ìu truÌc, lÃ¢Ì£p triÌnh hÆ°Æ¡Ìng ÄÃ´Ìi tÆ°Æ¡Ì£ng, lÃ¢Ì£p triÌnh Äa nhiá»m, song song; Giá»i thiá»u kyÌ thuÃ¢Ì£t thiÃªÌt kÃªÌ kiÃªÌn truÌc vaÌ giao diÃªÌ£n chÆ°Æ¡ng triÌnh. MÃ´n há»c thuá»c khoa CÃ´ng Nghá» Pháº§n Má»m'\n",
        "    monhoc['NT505'] = 'KhÃ³a luáº­n tá»t nghiá»p: Má»t cÃ´ng trÃ¬nh nghiÃªn cá»©u khoa há»c dÃ nh cho sinh viÃªn. Trong khÃ³a luáº­n, sinh viÃªn nÃªu rÃµ nhá»¯ng váº¥n Äá» do sinh viÃªn thá»±c hiá»n ÄÆ°á»£c dÆ°á»i sá»± hÆ°á»ng dáº«n cá»§a giáº£ng viÃªn nhÆ°: á»©ng dá»¥ng, quy trÃ¬nh hoáº¡t Äá»ng, há» thá»ng triá»n khai. NgoÃ i ra khÃ³a luáº­n cáº§n cÃ³ nhá»¯ng ÄÃ¡nh giÃ¡, phÆ°Æ¡ng hÆ°á»ng phÃ¡t triá»n tiáº¿p theo cá»§a Äá» tÃ i. Trong khÃ³a luáº­n nÃªu rÃµ káº¿t quáº£ thá»±c hiá»n cá»§a sinh viÃªn, ÄÃ¢y lÃ  thÃ nh pháº§n quan trá»ng nháº¥t cá»§a khÃ³a luáº­n. Äá» tÃ i khÃ³a luáº­n tá»t nghiá»p lÃ  má»t Äá» tÃ i ÄÆ°á»£c nghiÃªn cá»©u vÃ  triá»n khai chuyÃªn sÃ¢u gáº¯n vá»i yÃªu cáº§u thá»±c táº¿ cho tháº¥y kháº£ nÄng nghiÃªn cá»©u vÃ  lÃ m viá»c Äá»c láº­p cá»§a sinh viÃªn. Trong khÃ³a luáº­n tá»t nghiá»p, cáº§n xÃ¡c Äá»nh rÃµ nhá»¯ng váº¥n Äá» do sinh viÃªn thá»±c hiá»n ÄÆ°á»£c dÆ°á»i sá»± hÆ°á»ng dáº«n cá»§a giáº£ng viÃªn nhÆ°: á»©ng dá»¥ng, quy trÃ¬nh hoáº¡t Äá»ng, há» thá»ng triá»n khai, tÃ­nh má»i cá»§a nghiÃªn cá»©u. NgoÃ i ra khÃ³a luáº­n cáº§n cÃ³ nhá»¯ng ÄÃ¡nh giÃ¡, phÆ°Æ¡ng hÆ°á»ng phÃ¡t triá»n tiáº¿p theo cá»§a Äá» tÃ i. Trong khÃ³a luáº­n cáº§n nÃªu rÃµ káº¿t quáº£ nghiÃªn cá»©u cá»§a sinh viÃªn. MÃ´n há»c thuá»c khoa Máº¡ng MÃ¡y TÃ­nh vÃ  Truyá»n ThÃ´ng'\n",
        "    monhoc['NT211'] = 'An ninh nhÃ¢n sá»±, Äá»nh danh vÃ  chá»©ng thá»±c: KhÃ¡i niá»m cÄn báº£n vá» Äá»nh danh, xÃ¡c thá»±c vÃ  á»©ng dá»¥ng cá»§a chÃºng trong quáº£n lÃ½ truy cáº­p. MÃ´n há»c trang bá» cho sinh viÃªn ngÃ nh an ninh thÃ´ng tin: KhÃ¡i niá»m ná»n táº£ng vá» an ninh liÃªn quan tá»i con ngÆ°á»i; Kiáº¿n thá»©c vá» Äá»nh danh cÃ¹ng cÃ¡c cÃ´ng nghá» Äá»nh danh hiá»n Äáº¡i; Kiáº¿n thá»©c vá» xÃ¡c thá»±c vÃ  nhá»¯ng cÃ´ng nghá» liÃªn quan Äáº¿n xÃ¡c thá»±c; á»¨ng dá»¥ng Äá»nh danh vÃ  xÃ¡c thá»±c trong há» thá»ng CNTT. Äá»i vá»i há» Cá»­ nhÃ¢n tÃ i nÄng: TrÃ¬nh bÃ y chuyÃªn sÃ¢u hÆ¡n cÃ¡c ná»i dung Sinh tráº¯c vÃ  cÃ¡c phÆ°Æ¡ng phÃ¡p chÃ­nh; Quáº£n lÃ½ tÃ i khoáº£n vá»i Token; Quáº£n lÃ½ tÃ i khoáº£n liÃªn há»£p; Táº¥n cÃ´ng tháº» thÃ´ng minh; Bá» sung cÃ¡c bÃ i táº­p nÃ¢ng cao á» cÃ¡c ná»i dung trÃ¬nh bÃ y chuyÃªn sÃ¢u trÃªn vÃ  cÃ¡c ná»i dung Báº» máº­t kháº©u phá»©c táº¡p; Thiáº¿t káº¿, xÃ¢y dá»±ng vÃ  triá»n khai há» thá»ng cáº¥p chá»©ng chá» sá» á» quy mÃ´ lá»n. MÃ´n há»c thuá»c khoa Máº¡ng MÃ¡y TÃ­nh vÃ  Truyá»n ThÃ´ng'\n",
        "    monhoc['SE220'] = 'Thiáº¿t káº¿ Game: KiÃªÌn thÆ°Ìc, kyÌ nÄng liÌnh vÆ°Ì£c thiÃªÌt kÃªÌ game. LyÌ thuyÃªÌt vÃªÌ diÃªÌn biÃªÌn tÃ¢m lyÌ ngÆ°Æ¡Ìi chÆ¡i, baÌn chÃ¢Ìt cuÌa game, taÌ£i sao game hÃ¢Ìp dÃ¢Ìn. KyÌ thuÃ¢Ì£t thiÃªÌt kÃªÌ game, liÌ£ch sÆ°Ì trong thiÃªÌt kÃªÌ game. TÃ¢Ì£p trung vaÌo thiÃªÌt kÃªÌ giao diÃªÌ£n game nhÆ° caÌch xÃ¢y dÆ°Ì£ng menu, bÃ´Ì triÌ caÌc thaÌnh phÃ¢Ìn giao diÃªÌ£n, biÃªÌu tÆ°Æ¡Ì£ng, thiÃªÌt kÃªÌ HUD. BaÌn vÃªÌ thiÃªÌt kÃªÌ caÌnh chÆ¡i nhÆ° caÌch ÄÄÌ£t thÆ°Ì thaÌch, xÃ¢y dÆ°Ì£ng bÃ´Ìi caÌnh, taÌ£o hÃ´Ìn cho caÌnh chÆ¡i... MÃ´n há»c thuá»c khoa CÃ´ng Nghá» Pháº§n Má»m'\n",
        "    monhoc['SE320'] = 'Láº­p trÃ¬nh Äá» há»a 3 chiá»u vá»i Direct3D: LÃ¢Ì£p triÌnh Æ°Ìng duÌ£ng ÄÃ´Ì hoÌ£a 3 chiÃªÌu vaÌ hÆ°Æ¡Ìng dÃ¢Ìn sÆ°Ì duÌ£ng bÃ´Ì£ thÆ° viÃªÌ£n ÄÃ´Ì hoÌ£a DirectX ÄÃªÌ xÃ¢y dÆ°Ì£ng Æ°Ìng duÌ£ng. TriÌnh baÌy vÃªÌ cÆ¡ sÆ¡Ì toaÌn hoÌ£c Æ°Ìng duÌ£ng trong ÄÃ´Ì hoÌ£a 3 chiÃªÌu vaÌ quy triÌnh dÆ°Ì£ng hiÌnh 3 chiÃªÌu, triÌnh baÌy vÃªÌ Direct3D bao gÃ´Ìm caÌc vÃ¢Ìn ÄÃªÌ Äi tÆ°Ì cÆ¡ baÌn ÄÃªÌn nÃ¢ng cao, Æ°Ìng duÌ£ng caÌc kiÃªÌn thÆ°Ìc ÄaÌ hoÌ£c vaÌo xÃ¢y dÆ°Ì£ng troÌ chÆ¡i Tetris 3D. Káº¿t thÃºc khÃ³a há»c, sinh viÃªn sáº½ cÃ³ kháº£ nÄng tá»± thiáº¿t káº¿ vÃ  láº­p trÃ¬nh Æ°Ìng duÌ£ng Äá» há»a 3 chiá»u ÄÆ¡n giáº£n trÃªn mÃ´i trÆ°á»ng Windows. MÃ´n há»c thuá»c khoa CÃ´ng Nghá» Pháº§n Má»m'\n",
        "    monhoc['NT534'] = 'An toÃ n máº¡ng mÃ¡y tÃ­nh nÃ¢ng cao: CÃ¡ch phÃ²ng chá»ng táº¥n cÃ´ng tá»« chá»i dá»ch vá»¥, cÃ¡c hoáº¡t Äá»ng ngáº§m trÃªn Internet, bÃ n luáº­n vá» cÃ¡c giáº£i phÃ¡p kÄ© thuáº­t trong viá»c ngÄn cháº·n cÅ©ng nhÆ° Äá»i phÃ³ vá»i ngÄn cháº·n trong viá»c quáº£n lÃ½ truy cáº­p trÃªn Internet. NgoÃ i ra, mÃ´n nÃ y cÅ©ng Äá» cáº­p cÃ¡c nguy cÆ¡ tá»« cÃ¡c loáº¡i mÃ£ Äá»c tinh vi Äá»i vá»i an toÃ n máº¡ng. Äá»i vá»i há» tÃ i nÄng: MÃ´n an toÃ n máº¡ng Äá» cáº­p cÃ¡c chá»§ Äá» cÄn báº£n cá»§a an toÃ n máº¡ng. MÃ´n nÃ y Äá» cáº­p Äáº¿n cÃ¡c váº¥n Äá» chuyÃªn sÃ¢u hÆ¡n vÃ­ dá»¥ nhÆ° lÃ  lÃ m tháº¿ nÃ o Äá» phÃ²ng chá»ng táº¥n cÃ´ng tá»« chá»i dá»ch vá»¥, cÃ¡c hoáº¡t Äá»ng ngáº§m trÃªn Internet, bÃ n luáº­n vá» cÃ¡c giáº£i phÃ¡p kÄ© thuáº­t trong viá»c ngÄn cháº·n cÅ©ng nhÆ° Äá»i phÃ³ vá»i ngÄn cháº·n trong viá»c quáº£n lÃ½ truy cáº­p trÃªn Internet. NgoÃ i ra, mÃ´n nÃ y cÅ©ng Äá» cáº­p cÃ¡c nguy cÆ¡ tá»« cÃ¡c loáº¡i mÃ£ Äá»c tinh vi Äá»i vá»i an toÃ n máº¡ng. Cuá»i cÃ¹ng, cÃ¡c ká»¹ thuáº­t client side, server-side honeypot cÅ©ng ÄÆ°á»£c giá»i thiá»u Äá» nghiÃªn cá»©u, thu tháº­p mÃ£ Äá»c. MÃ´n há»c thuá»c khoa Máº¡ng MÃ¡y TÃ­nh vÃ  Truyá»n ThÃ´ng'\n",
        "    monhoc['IE307'] = 'CÃ´ng nghá» láº­p trÃ¬nh Äa ná»n táº£ng cho á»©ng dá»¥ng di Äá»ng: MÃ´n há»c trÃ¬nh bÃ y nguyÃªn lÃ½ cÆ¡ báº£n cá»§a cÃ¡c Framework vá» láº­p trÃ¬nh di Äá»ng Äa ná»n táº£ng (React Native, PhoneGap, Xamarin...) vÃ  Äáº·c biá»t lÃ  Xamarin Framework. Cung cáº¥p cÃ¡c Controls cÆ¡ báº£n cá»§a Xamarin, vÃ  Ã¡p dá»¥ng Äá» xÃ¢y dá»±ng á»©ng dá»¥ng Äa ná»n táº£ng: Label, Entry, Button, Image, Switch, ListView, DatePicker, TimePicker. BÃªn cáº¡nh ÄÃ³, mÃ´n há»c cÃ²n cung cáº¥p thÃªm cÃ¡c váº¥n Äá» nÃ¢ng cao cá»§a Xamarin, Äá» tiáº¿p tá»¥c tá»± nghiÃªn cá»©u sá»­ dá»¥ng vá» sau cá»§a Camera, Notification, Google Map APIs, Grial, RESTful API, Syncfusion... MÃ´n há»c trang bá» ká»¹ nÄng lÃ m viá»c nhÃ³m theo mÃ´i trÆ°á»ng doanh nghiá»p, Äá»c hiá»u yÃªu cáº§u cá»§a khÃ¡ch hÃ ng vá» á»©ng dá»¥ng di Äá»ng, PhÃ¢n tÃ­ch & Thiáº¿t káº¿ cÃ¡c á»©ng dá»¥ng di Äá»ng Äá» xÃ¢y dá»±ng má»t á»©ng dá»¥ng di Äá»ng Äa ná»n táº£ng cÆ¡ báº£n cháº¡y trÃªn iOS, Android & Windows Phone theo yÃªu cáº§u. MÃ´n há»c thuá»c khoa KÄ© Thuáº­t ThÃ´ng Tin'\n",
        "    lst_input_ids = [torch.tensor([tokenizer.encode(monhoc[key])]) for key in lst_keys]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        features = {}\n",
        "        for index, input_ids in enumerate(lst_input_ids):\n",
        "            features[lst_keys[index]] = phobert(input_ids).pooler_output\n",
        "\n",
        "    lst_supervision_extra_dic = {\n",
        "        'nganh_CNPM': 'Cung cáº¥p sá»± hiá»u biáº¿t cÃ¡c Äáº·c trÆ°ng chÃ­nh cá»§a pháº§n má»m, khÃ¡i niá»m chu trÃ¬nh pháº§n má»m, cÃ¡c hoáº¡t Äá»ng ká»¹ thuáº­t, cung cáº¥p kiáº¿n thá»©c thá»±c nghiá»m vá» chá»n lá»±a ká»¹ thuáº­t, cÃ´ng cá»¥, mÃ´ hÃ¬nh chu trÃ¬nh dá»± Ã¡n, cÃ¡c kiáº¿n thá»©c Äá» quan trá»ng Äáº£m báº£o cháº¥t lÆ°á»£ng (quality assurance), quáº£n lÃ½ dá»± Ã¡n trong phÃ¡t triá»n pháº§n má»m',\n",
        "        'nganh_HTTT': 'NghiÃªn cá»©u cÃ¡c há» thá»ng thÃ´ng tin quáº£n trá» doanh nghiá»p, ngÃ¢n hÃ ng nhÆ° ERP, Supply Chain Management; NghiÃªn cá»©u cÃ¡c á»©ng dá»¥ng xÃ¢y dá»±ng há» thá»ng thÃ´ng tin phá»¥c vá»¥ ThÆ°Æ¡ng Máº¡i Äiá»n Tá»­; PhÃ¡t triá»n cÃ¡c nghiÃªn cá»©u nháº±m tÄng cÆ°á»ng khai thÃ¡c tri thá»©c tá»« CSDL, quáº£n trá» cÃ¡c kho dá»¯ liá»u lá»n, tÃ¬m kiáº¿m thÃ´ng tin trÃªn web, tÃ¬m kiáº¿m ngá»¯ nghÄ©a, máº¡ng xÃ£ há»i; PhÃ¡t triá»n cÃ¡c nghiÃªn cá»©u liÃªn ngÃ nh giá»¯a tin há»c vÃ  cÃ¡c ngÃ nh khoa há»c khÃ¡c nhÆ°: xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn, sinh há»c, hoÃ¡ há»c, mÃ´i trÆ°á»ng, ...',\n",
        "        'nganh_KHMT': 'ÄÃ o táº¡o bÃ i báº£n vá» TrÃ­ tuá» nhÃ¢n táº¡o (Artificial Intelligence - AI) ÄÃ¡p á»©ng nhu cáº§u vá» nghiÃªn cá»©u, xÃ¢y dá»±ng vÃ  phÃ¡t triá»n cÃ¡c sáº£n pháº©m, giáº£i phÃ¡p thÃ´ng minh phá»¥c vá»¥ cho cuá»c sá»ng. ChÆ°Æ¡ng trÃ¬nh ÄÃ o táº¡o cá»§a Khoa cung cáº¥p cho sinh viÃªn nhiá»u lá»±a chá»n theo cÃ¡c Äá»nh hÆ°á»ng nghá» nghiá»p nhÆ° TrÃ­ tuá» NhÃ¢n táº¡o (AI), Thá» giÃ¡c MÃ¡y tÃ­nh (Computer Vision), Xá»­ lÃ½ NgÃ´n ngá»¯ Tá»± nhiÃªn (Natural Language Processing)â¦. Vá»i cÃ¡c kiáº¿n thá»©c ná»n táº£ng sinh viÃªn hoÃ n toÃ n cÃ³ thá» tham gia nghiÃªn cá»©u vÃ  phÃ¡t triá»n cÃ¡c á»©ng dá»¥ng thÃ´ng minh nhÆ°: há» thá»ng nháº­n diá»n khuÃ´n máº·t (Face Recognition System), há» thá»ng Chatbot, há» thá»ng tÃ¬m kiáº¿m â truy váº¥n thÃ´ng tin (Retrieval System) ...',\n",
        "        'nganh_KTMT': 'Láº­p trÃ¬nh cÃ¡c pháº§n má»m nhÃºng trÃªn cÃ¡c thiáº¿t bá» di Äá»ng (Smartphone, Tablet, iphone, ipad, ...), cÃ¡c vi xá»­ lÃ½-vi Äiá»u khiá»n trong cÃ¡c há» thá»ng cÃ´ng nghiá»p, xe Ã´ tÃ´, Äiá»n gia dá»¥ng, ngÃ´i nhÃ  thÃ´ng minh,â¦ (ChuyÃªn ngÃ nh há» thá»ng nhÃºng vÃ  IoT); thiáº¿t káº¿ máº¡ch Äiá»n - Äiá»n tá»­, máº¡ch Äiá»u khiá»n trong cÃ´ng nghiá»p, vi máº¡ch, chip,... (ChuyÃªn ngÃ nh thiáº¿t káº¿ vi máº¡ch)',\n",
        "        'nganh_KTTT': 'Thiáº¿t káº¿, xÃ¢y dá»±ng vÃ  quáº£n lÃ½ cÃ¡c dá»± Ã¡n nghiÃªn cá»©u vÃ  á»©ng dá»¥ng CNTT, chá»§ yáº¿u trong lÄ©nh vá»±c dá»¯ liá»u khÃ´ng gian-thá»i gian (Äá»a lÃ½, tÃ i nguyÃªn, mÃ´i trÆ°á»ng, viá»n thÃ¡m. . .). Táº­p trung vÃ o nhá»¯ng á»©ng dá»¥ng vá» GIS trÃªn thiáº¿t bá» di Äá»ng vÃ  trao Äá»i dá»¯ liá»u vá»i mÃ¡y chá»§; Váº­n hÃ nh, quáº£n lÃ½, giÃ¡m sÃ¡t; phÃ¢n tÃ­ch vÃ  phÃ¡t triá»n cÃ¡c á»©ng dá»¥ng CNTT táº¡i cÃ¡c doanh nghiá»p; Khai thÃ¡c dá»¯ liá»u vÃ  thÃ´ng tin á»©ng dá»¥ng cho cÃ¡c doanh nghiá»p trong váº¥n Äá» phÃ¢n tÃ­ch Äá»nh lÆ°á»£ng; XÃ¢y dá»±ng, phÃ¡t triá»n cÃ¡c á»©ng dá»¥ng vá» lÃ£nh vá»±c truyá»n thÃ´ng xÃ£ há»i vÃ  cÃ´ng nghá» Web',\n",
        "        'nganh_MMT&TT': 'Quáº£n trá» máº¡ng vÃ  há» thá»ng táº¡i cÃ¡c ngÃ¢n hÃ ng, cÃ¡c trung tÃ¢m dá»¯ liá»u, cÃ¡c nhÃ  cung cáº¥p dá»ch vá»¥ Internet (ISP); Thiáº¿t káº¿ máº¡ng chuyÃªn nghiá»p: xÃ¢y dá»±ng cÃ¡c máº¡ng mÃ¡y tÃ­nh an toÃ n, hiá»u quáº£ cho cÃ¡c ÄÆ¡n vá» cÃ³ yÃªu cáº§u; PhÃ¡t triá»n pháº§n má»m máº¡ng; PhÃ¡t triá»n pháº§n má»m máº¡ng; XÃ¢y dá»±ng vÃ  phÃ¡t triá»n cÃ¡c á»©ng dá»¥ng truyá»n thÃ´ng: VoIP, há»i nghá» truyá»n hÃ¬nh',\n",
        "    }\n",
        "    lst_supervision_keys = list(lst_supervision_extra_dic.keys())\n",
        "    lst_supervision_token = [torch.tensor([tokenizer.encode(lst_supervision_extra_dic[key])]) for key in ['nganh_CNPM', 'nganh_HTTT', 'nganh_KHMT', 'nganh_KTMT', 'nganh_KTTT', 'nganh_MMT&TT']]\n",
        "    with torch.no_grad():\n",
        "        features_supervision = {}\n",
        "        for index, input_ids in enumerate(lst_supervision_token):\n",
        "            features_supervision[lst_supervision_keys[index]] = phobert(input_ids).pooler_output\n",
        "\n",
        "    data_temp = dataset_original[['mamh', 'nganh_BB', 'nganh_BMAV', 'nganh_CNPM', 'nganh_HTTT', 'nganh_KHMT', 'nganh_KTMT', 'nganh_KTTT', 'nganh_MMT&TT']]\n",
        "\n",
        "    conditions = [\n",
        "        dataset_original['nganh_BB'] == 1,\n",
        "        dataset_original['nganh_BMAV'] == 1,\n",
        "        dataset_original['nganh_CNPM'] == 1,\n",
        "        dataset_original['nganh_HTTT'] == 1,\n",
        "        dataset_original['nganh_KHMT'] == 1,\n",
        "        dataset_original['nganh_KTMT'] == 1,\n",
        "        dataset_original['nganh_KTTT'] == 1,\n",
        "        dataset_original['nganh_MMT&TT'] == 1   \n",
        "    ]\n",
        "    values = ['nganh_BB', 'nganh_BMAV', 'nganh_CNPM', 'nganh_HTTT', 'nganh_KHMT', 'nganh_KTMT', 'nganh_KTTT', 'nganh_MMT&TT']\n",
        "    data_temp['nganh'] = np.select(conditions, values, default=0)\n",
        "\n",
        "    data_temp = data_temp.drop_duplicates()\n",
        "\n",
        "    for index, key in enumerate(features.keys()):\n",
        "        val = data_temp.loc[data_temp['mamh'] == key, 'nganh'].values[0]\n",
        "        if val in ['nganh_BB', 'nganh_BMAV']:\n",
        "            continue\n",
        "        else:\n",
        "            features[key] = torch.cat((features[key], features_supervision[val]), 1)\n",
        "    data = [{\n",
        "            'mh1': i, \n",
        "            'mh2': j, \n",
        "            'similarity': cosine_similarity(features[i], features[j]).item()\n",
        "        } \\\n",
        "        for i in features.keys() \\\n",
        "        for j in features.keys()]\n",
        "    attention_monhoc = pd.DataFrame(data)\n",
        "    attention_matrix = attention_monhoc.pivot_table(index=[\"mh1\"], columns=[\"mh2\"], values=\"similarity\")\n",
        "    # attention_matrix.to_csv('../../dataset/attention_matrix.csv')\n",
        "    return attention_matrix"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CLGFQ9KZpZW3"
      },
      "source": [
        "### Get related subjects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfRh6nU4lDSS",
        "outputId": "3b0edb7c-e300-488c-d4b4-d24637478f48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 1.12 ms (started: 2023-06-06 07:27:53 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Phase 1\n",
        "def get_related_subjects(\n",
        "        mamh_query=None, \n",
        "        attention_matrix=None, \n",
        "        k_threshold=20):\n",
        "    \n",
        "    si = attention_matrix[mamh_query]\n",
        "    rcm_df = pd.DataFrame(attention_matrix.corrwith(si).sort_values(ascending=False)).reset_index(drop=False)\n",
        "    rcm_df = rcm_df.rename(columns={rcm_df.columns[0]: 'mamh'})\n",
        "    related_subjects = rcm_df.head(k_threshold)['mamh'].tolist()\n",
        "    return related_subjects"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_4oLR-lVpc49"
      },
      "source": [
        "### Get related students"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNJYa_Knl9DU",
        "outputId": "ee9bc3e4-772b-4ac5-ab93-3808da7188cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 1.83 ms (started: 2023-06-06 07:27:53 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Phase 2\n",
        "def get_related_students(\n",
        "        dataset_original=None, \n",
        "        mamh_query=None, \n",
        "        mssv_query=None,\n",
        "        t_threshold=8):\n",
        "    \n",
        "    df_students = dataset_original[[\n",
        "        'mssv', 'gioitinh', \n",
        "        'CNPM', 'HTTT', 'KHMT', 'KTMT', 'KTTT', 'MMT&TT',   \\\n",
        "        'CLC', 'CNTN', 'CQUI', 'CTTT', 'KSTN',  \\\n",
        "        'mamh',     \\\n",
        "        'diem_hp',      \\\n",
        "    ]]\n",
        "    df_students = df_students[df_students['mamh'].isin(['IT001', 'IT002' ,'IT003', 'IT004', 'IT005', 'IT006', 'IT007'] + [mamh_query])]\n",
        "    one_hot_encoded = pd.pivot_table(data=df_students, index=df_students.index, columns='mamh', values='diem_hp', fill_value=-10.0)\n",
        "\n",
        "    # Concatenate the one-hot encoded columns with the original DataFrame\n",
        "    df_students_encoded = pd.concat([df_students, one_hot_encoded], axis=1)\n",
        "    df_students_merged = df_students_encoded.groupby('mssv').max().reset_index()\n",
        "    df_students_merged = df_students_merged.drop(columns=['mamh', 'diem_hp'])\n",
        "    \n",
        "    similarity_matrix = cosine_similarity(df_students_merged.iloc[:, 1:])\n",
        "    similarity_df = pd.DataFrame(similarity_matrix, index=df_students_merged['mssv'], columns=df_students_merged['mssv'])\n",
        "    float_list = np.arange(0.993, 0.998 + 0.0001, 0.0001).tolist()\n",
        "    for thr in float_list:\n",
        "        list_related_students = similarity_df[(similarity_df[mssv_query] > thr) & (similarity_df.index != mssv_query)].index\n",
        "        if len(list_related_students) != 0 and len(list_related_students) <= t_threshold:\n",
        "            break\n",
        "    return list_related_students"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1jqX4LpPpgZJ"
      },
      "source": [
        "### Get score single"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxT58fsElaxM",
        "outputId": "06031ed2-930b-432b-9993-ee733e705db3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 1.47 ms (started: 2023-06-06 07:27:53 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Phase calculate score\n",
        "def get_score_single(\n",
        "        dataset_original,\n",
        "        list_related_subjects=None,\n",
        "        list_related_students=None,\n",
        "        mamh_query=None,\n",
        "        mssv_query=None):\n",
        "    \n",
        "    if len(list_related_students) == 0:\n",
        "        return [], 0.0\n",
        "    for index, student in enumerate(list_related_students):\n",
        "        history_subjects = list(dataset_original[dataset_original['mssv'].isin([student])]['mamh'].unique())\n",
        "        if index == 0:\n",
        "            intersection = list(set(history_subjects) & set(list_related_subjects))\n",
        "        else:\n",
        "            intersection = list(set(history_subjects) & set(intersection))\n",
        "\n",
        "    intersection.remove(mamh_query)\n",
        "    if len(intersection) == 0:\n",
        "        return [], 0.0\n",
        "    sv_subjects = list(dataset_original[dataset_original['mssv'].isin([mssv_query])]['mamh'].unique())\n",
        "    result = list(set(sv_subjects) & set(intersection))\n",
        "    score_result = len(result) / len(intersection)\n",
        "    return (intersection, score_result)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "msfdrBSWpkto"
      },
      "source": [
        "# Inference 1 data point"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sE2Z5Im-pp5o",
        "outputId": "9372ca44-2dd3-4e2f-a87f-00d048c2f6f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 404 Âµs (started: 2023-06-06 07:27:53 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# ten_mh = 'CS112'\n",
        "# mssv = 'EAA0B693XPvAibaEXe99j2P15eeB04XwhZ0tzlI4'\n",
        "# attention_matrix = pd.read_csv('../../dataset/attention_matrix.csv')\n",
        "# ### Retrained entire to get Attention matrix, this progress take about 2, 3 minutes\n",
        "# attention_matrix = get_attention_matrix(\n",
        "#     dataset=dataset,\n",
        "#     dataset_original=dataset_original,\n",
        "#     phobert=phobert,\n",
        "#     tokenizer=tokenizer\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2R6RY3QNqeOQ",
        "outputId": "97ea6016-c184-4157-ffa1-9fee8fdde3b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 410 Âµs (started: 2023-06-06 07:27:53 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# from sklearn.metrics.pairwise import cosine_similarity\n",
        "# list_related_subjects = get_related_subjects(\n",
        "#     mamh_query=ten_mh, \n",
        "#     attention_matrix=attention_matrix,\n",
        "#     k_threshold=20)\n",
        "\n",
        "# list_related_students = get_related_students(\n",
        "#     dataset_original=dataset_original, \n",
        "#     mamh_query=ten_mh, \n",
        "#     mssv_query=mssv,\n",
        "#     t_threshold=0.995)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYvUxF-NokY0",
        "outputId": "7320f7d0-ef31-4814-e6df-38e626572832"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 439 Âµs (started: 2023-06-06 07:27:53 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# result = get_score_single(\n",
        "#     dataset_original=dataset_original,\n",
        "#     list_related_subjects=list_related_subjects,\n",
        "#     list_related_students=list_related_students,\n",
        "#     mamh_query=ten_mh,\n",
        "#     mssv_query=mssv)\n",
        "\n",
        "# result"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "06tLfZ9hwE38"
      },
      "source": [
        "# Training models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lW6Wp-TOwF1l"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "from tqdm import tqdm\n",
        "attention_matrix = pd.read_csv('../../dataset/attention_matrix.csv')\n",
        "i = 15\n",
        "while 15 <= i and i <= 22:\n",
        "    j = 3\n",
        "    while 3 <= j and j <= 10:\n",
        "        dataset_train = dataset_original.drop(dataset_original[(dataset_original['nganh_BB'] == 1) | (dataset_original['nganh_BMAV'] == 1)].index)\n",
        "        lst_users = list(dataset_train['mssv'].unique())\n",
        "        score = 0.0\n",
        "        lst_count = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "        print(f'\\nthreshold_get_subjects: {i}, threshold_get_students: {j}')\n",
        "\n",
        "        for index_user, user in tqdm(enumerate(lst_users)):\n",
        "\n",
        "            if index_user == 5:\n",
        "                break\n",
        "\n",
        "            data_user = filter(dataset_train, 'mssv', [user])\n",
        "            data_user.drop_duplicates(subset=['mssv', 'mamh'], keep='last', inplace=False)\n",
        "\n",
        "            lst_user_mamh = list(data_user['mamh'])\n",
        "            # print(f'\\nUser: {index_user+1} with the number of subjects: {len(lst_user_mamh)} -------------')\n",
        "            result_user_single = 0.0\n",
        "            for index, user_mamh in enumerate(lst_user_mamh):\n",
        "                list_related_subjects = get_related_subjects(\n",
        "                    mamh_query=user_mamh, \n",
        "                    attention_matrix=attention_matrix,\n",
        "                    k_threshold=i)\n",
        "                \n",
        "                list_related_students = get_related_students(\n",
        "                    dataset_original=dataset_original, \n",
        "                    mamh_query=user_mamh, \n",
        "                    mssv_query=user,\n",
        "                    t_threshold=j)\n",
        "                \n",
        "                list_result, result = get_score_single(\n",
        "                    dataset_original=dataset_original,\n",
        "                    list_related_subjects=list_related_subjects,\n",
        "                    list_related_students=list_related_students,\n",
        "                    mamh_query=user_mamh,\n",
        "                    mssv_query=user)\n",
        "                # print(f'\\nUser: {user} ------ Subject: {user_mamh} ------ list: {list_result} ------ Score = {round(result, 2)}')\n",
        "                if len(list_result) <= 7:\n",
        "                    lst_count[len(list_result)] += 1\n",
        "                else:\n",
        "                    lst_count[-1] += 1\n",
        "\n",
        "                result_user_single += result\n",
        "            # print(f'Total loss single for {user}: {result_user_single / len(lst_user_mamh)}')\n",
        "            # print(f'\\n================================================================================\\n')\n",
        "            \n",
        "            score += (result_user_single / (index + 1))\n",
        "\n",
        "        print(f'Total score: {score * 100 / (index_user + 1)}')\n",
        "        print(f'Count: {lst_count}')\n",
        "\n",
        "        with open('../../example.txt', 'a') as file:\n",
        "            file.write(f'threshold_get_subjects: {i}, threshold_get_students: {j}, score: {score * 100 / 5}, count: {lst_count}\\n')\n",
        "\n",
        "        j += 1\n",
        "    i += 1"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lix9ycROjVer"
      },
      "source": [
        "### Add data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVJXfQ5qjU-b",
        "outputId": "29369220-8dd2-4291-e5de-da2c6d8642ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 1.3 ms (started: 2023-06-06 07:28:38 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def input_prediction(\n",
        "    _mssv = None,\n",
        "    _gioitinh = None,\n",
        "    _khoa = None,\n",
        "    _hedaotao = None,\n",
        "    _mamh = None,\n",
        "    _ten_mh = None,\n",
        "    _diem_hp = None,\n",
        "):\n",
        "    new_data_point = {\n",
        "        'mssv': _mssv,\n",
        "        'gioitinh': 1 if _gioitinh == 'Nam' else 0,\n",
        "        # khoa\n",
        "        'CNPM': 1 if _khoa == 'CNPM' else 0,\n",
        "        'HTTT': 1 if _khoa == 'HTTT' else 0,\n",
        "        'KHMT': 1 if _khoa == 'KHMT' else 0,\n",
        "        'KTMT': 1 if _khoa == 'KTMT' else 0,\n",
        "        'KTTT': 1 if _khoa == 'KTTT' else 0,\n",
        "        'MMT&TT': 1 if _khoa == 'MMT&TT' else 0,\n",
        "\n",
        "        # he dao tao\n",
        "        'CLC': 1 if _hedaotao == 'CLC' else 0,\n",
        "        'CNTN': 1 if _hedaotao == 'CNTN' else 0,\n",
        "        'CQUI': 1 if _hedaotao == 'CQUI' else 0,\n",
        "        'CTTT': 1 if _hedaotao == 'CTTT' else 0,\n",
        "        'KSTN': 1 if _hedaotao == 'KSTN' else 0,\n",
        "\n",
        "        # diem hoc phan\n",
        "        'diem_hp': _diem_hp,\n",
        "    }\n",
        "\n",
        "    # new_data_point\n",
        "    return new_data_point"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2u-eH8Rm8Kd",
        "outputId": "eb54ca02-dfe1-4367-c185-b60e52812174"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 35.5 ms (started: 2023-06-06 07:37:03 +00:00)\n"
          ]
        }
      ],
      "source": [
        "dataset_original = dataset_original.append([\n",
        "    input_prediction(_mssv = '20521494', _gioitinh = 'Nam', _khoa = 'KHMT', _hedaotao = 'CQUI', _mamh = 'IT001', _diem_hp = 8.1,),\n",
        "    input_prediction(_mssv = '20521494', _gioitinh = 'Nam', _khoa = 'KHMT', _hedaotao = 'CQUI', _mamh = 'IT002', _diem_hp = 8.5,),\n",
        "    input_prediction(_mssv = '20521494', _gioitinh = 'Nam', _khoa = 'KHMT', _hedaotao = 'CQUI', _mamh = 'IT003', _diem_hp = 9.4,),\n",
        "    input_prediction(_mssv = '20521494', _gioitinh = 'Nam', _khoa = 'KHMT', _hedaotao = 'CQUI', _mamh = 'IT004', _diem_hp = 7.7,),\n",
        "    input_prediction(_mssv = '20521494', _gioitinh = 'Nam', _khoa = 'KHMT', _hedaotao = 'CQUI', _mamh = 'IT005', _diem_hp = 8.1,),\n",
        "    input_prediction(_mssv = '20521494', _gioitinh = 'Nam', _khoa = 'KHMT', _hedaotao = 'CQUI', _mamh = 'IT006', _diem_hp = -10.0,),\n",
        "    input_prediction(_mssv = '20521494', _gioitinh = 'Nam', _khoa = 'KHMT', _hedaotao = 'CQUI', _mamh = 'IT007', _diem_hp = 9.3,),\n",
        "], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-RJYf9Vt6C5",
        "outputId": "4c7b83ec-b913-4eca-ea8d-edef00164553"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'datetime.datetime'>\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# Get the current time\n",
        "current_time = datetime.now()\n",
        "\n",
        "# Print the current time\n",
        "print(type(current_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZCiNcNBt6iX",
        "outputId": "996992e4-344d-43ff-f51e-7059c711bba3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-06-07 00:19:57.909699+07:00\n",
            "2023 6 7 0 19 57 909699\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "import pytz\n",
        "\n",
        "# Set the desired timezone (Vietnam)\n",
        "timezone = pytz.timezone('Asia/Ho_Chi_Minh')\n",
        "\n",
        "# Get the current time in Vietnam\n",
        "current_time = datetime.now(timezone)\n",
        "\n",
        "# Print the current time\n",
        "print(current_time)\n",
        "year = current_time.year\n",
        "month = current_time.month\n",
        "day = current_time.day\n",
        "hour = current_time.hour\n",
        "minute = current_time.minute\n",
        "second = current_time.second\n",
        "microsecond = current_time.microsecond\n",
        "\n",
        "print(year, month, day, hour, minute, second, microsecond)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "NKTMNa12_Sm7"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
